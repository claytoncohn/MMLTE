{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Clayton Cohn<br>\n",
        "6 Nov 2023<br>\n",
        "OELE Lab<br>\n",
        "Vanderbilt University\n",
        "\n",
        "#<center> S18 Cohen's *k* and Spreadsheet Creation"
      ],
      "metadata": {
        "id": "MbtZ8iidtVQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction and Attribution\n",
        "\n",
        "This notebook was create by Clayton Cohn for the purpose of calculating Cohen's *k* and creating the MMLTE survey's final consensus document.\n",
        "\n",
        "In this notebook, we will:\n",
        "*   Calculate Cohen's k for the additional extracted features\n",
        "*   Export final consensus and spreadsheet\n",
        "\n",
        "The MMLTE survey project is a collaborative effor between Dr. Gautam Biswas, Clayton Cohn, Eduardo Davalos, Joyce Fonteles, Dr. Meiyi Ma, Caleb Vatral, and Hanchen (David) Wang."
      ],
      "metadata": {
        "id": "10r0tE3zKlMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Import"
      ],
      "metadata": {
        "id": "KQofVjXmqalW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdabTZPdpCs4",
        "outputId": "818a4e83-44fa-4481-f499-152cbefbf64c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "S18_PATH = \"drive/My Drive/Clayton/20230420_MMLTE/S18_IRR_and_Consensus.csv\""
      ],
      "metadata": {
        "id": "F7V8sEagq0wM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display max rows, columns, column length\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "df = pd.read_csv(S18_PATH,header=0)\n",
        "\n",
        "for col in df:\n",
        "  if col not in {\"Analysis Results (w/ multimodal advantages)\",\"Reviewer Notes\"}:\n",
        "    assert not df[col].isnull().values.any(), print(col)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tuftYmRbrDV5",
        "outputId": "61a97013-16c0-486e-ef22-27e4849d27b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         UUID  \\\n",
              "0  1326191931   \n",
              "1  1326191931   \n",
              "2  1326191931   \n",
              "3  1469065963   \n",
              "4  1469065963   \n",
              "\n",
              "                                                                                                             Title  \\\n",
              "0                                                          multimodal learning analytics in a laboratory classroom   \n",
              "1                                                          multimodal learning analytics in a laboratory classroom   \n",
              "2                                                          multimodal learning analytics in a laboratory classroom   \n",
              "3  examining socially shared regulation and shared physiological arousal events with multimodal learning analytics   \n",
              "4  examining socially shared regulation and shared physiological arousal events with multimodal learning analytics   \n",
              "\n",
              "     Mapped First Author  Year Environment Type (learning or training)  \\\n",
              "0  Man Ching Esther Chan  2019                                Learning   \n",
              "1  Man Ching Esther Chan  2019                                Learning   \n",
              "2  Man Ching Esther Chan  2019                                Learning   \n",
              "3            Andy Nguyen  2022                                Learning   \n",
              "4            Andy Nguyen  2022                                Learning   \n",
              "\n",
              "  Mapped Data Collection Mediums Mapped Modalities Mapped Analysis Methods  \\\n",
              "0                    VIDEO,AUDIO    POSE,GAZE,PROS               CLS,CLUST   \n",
              "1                    VIDEO,AUDIO    POSE,GAZE,PROS               CLS,CLUST   \n",
              "2                    VIDEO,AUDIO    POSE,GAZE,PROS               CLS,CLUST   \n",
              "3             VIDEO,AUDIO,SENSOR          QUAL,EDA          PATT,CLS,CLUST   \n",
              "4             VIDEO,AUDIO,SENSOR          QUAL,EDA          PATT,CLS,CLUST   \n",
              "\n",
              "  Mapped Fusion Types Mapped Publication Acronym  \\\n",
              "0                LATE                     MLPALA   \n",
              "1                LATE                     MLPALA   \n",
              "2                LATE                     MLPALA   \n",
              "3              HYBRID                       BJET   \n",
              "4              HYBRID                       BJET   \n",
              "\n",
              "                                      Mapped Full Publication  Sort Number  \\\n",
              "0  Machine Learning Paradigms: Advances in Learning Analytics            3   \n",
              "1  Machine Learning Paradigms: Advances in Learning Analytics            3   \n",
              "2  Machine Learning Paradigms: Advances in Learning Analytics            3   \n",
              "3                   British Journal of Educational Technology            4   \n",
              "4                   British Journal of Educational Technology            4   \n",
              "\n",
              "  Environment Setting Environment Subject Participant Structure  \\\n",
              "0                PHYS                STEM            IND, MULTI   \n",
              "1                PHYS                STEM            IND, MULTI   \n",
              "2                PHYS                STEM            IND, MULTI   \n",
              "3                PHYS                STEM                 MULTI   \n",
              "4                PHYS                STEM                 MULTI   \n",
              "\n",
              "  Didactic Nature Level of Instruction or Training Analysis Approach  \\\n",
              "0           INSTR                             UNSP                MB   \n",
              "1           INSTR                             UNSP                MB   \n",
              "2           INSTR                             UNSP                MB   \n",
              "3           INSTR                              K12                MB   \n",
              "4           INSTR                              K12                MB   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                               Analysis Results (w/ multimodal advantages)  \\\n",
              "0                                                                                                                                                                                                                                                                   The MMLA techniques applied were able to successfully extract relevant features to quantify and visualize teacher and student behaviors and activities related to student engagement based on the classroom video and audio recordings   \n",
              "1                                                                                                                                                                                                                                                          Within heavily rigged smart classroom, visual (gaze, posture) and auditory (speech levels) were extracted via AI and were then used (rule's based approach -> model) to compute student's engagement in individual, pair, and group structures.   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN   \n",
              "3  Results indicate that physiological arousal could indicate engagement in metacognitive interactions, provided evidence for physiological activities as triggers for adaptive loops of learning regulation in collaborative learning. They utilised the CNN model to classify the sequences of regulatory activities and Shared Physiological Arousal Events moments and results have provided a proof of concept and indicated the potential of using ML for predicting collaborative learning success.   \n",
              "4                                                                                                             The paper explores the correlation of physiological signals to metacognition interactions in a collaborative setting. Two researchers video coded sessions into sequences of interactions. With these sequences, Markov chains were made and a 1D CNN (input physiological signal, output interaction label) was trained, with preliminary results that suggest a possible future direction.   \n",
              "\n",
              "  Full-Read 3 by Researcher Reviewer Reviewer Notes  \n",
              "0                     Joyce        1            NaN  \n",
              "1                   Eduardo        2            NaN  \n",
              "2             Joyce/Eduardo      1&2            NaN  \n",
              "3                     Joyce        1            NaN  \n",
              "4                   Eduardo        2            NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e47cede-64b8-4263-9e3b-e3dd9992f582\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UUID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Mapped First Author</th>\n",
              "      <th>Year</th>\n",
              "      <th>Environment Type (learning or training)</th>\n",
              "      <th>Mapped Data Collection Mediums</th>\n",
              "      <th>Mapped Modalities</th>\n",
              "      <th>Mapped Analysis Methods</th>\n",
              "      <th>Mapped Fusion Types</th>\n",
              "      <th>Mapped Publication Acronym</th>\n",
              "      <th>Mapped Full Publication</th>\n",
              "      <th>Sort Number</th>\n",
              "      <th>Environment Setting</th>\n",
              "      <th>Environment Subject</th>\n",
              "      <th>Participant Structure</th>\n",
              "      <th>Didactic Nature</th>\n",
              "      <th>Level of Instruction or Training</th>\n",
              "      <th>Analysis Approach</th>\n",
              "      <th>Analysis Results (w/ multimodal advantages)</th>\n",
              "      <th>Full-Read 3 by Researcher</th>\n",
              "      <th>Reviewer</th>\n",
              "      <th>Reviewer Notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1326191931</td>\n",
              "      <td>multimodal learning analytics in a laboratory classroom</td>\n",
              "      <td>Man Ching Esther Chan</td>\n",
              "      <td>2019</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO</td>\n",
              "      <td>POSE,GAZE,PROS</td>\n",
              "      <td>CLS,CLUST</td>\n",
              "      <td>LATE</td>\n",
              "      <td>MLPALA</td>\n",
              "      <td>Machine Learning Paradigms: Advances in Learning Analytics</td>\n",
              "      <td>3</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND, MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>MB</td>\n",
              "      <td>The MMLA techniques applied were able to successfully extract relevant features to quantify and visualize teacher and student behaviors and activities related to student engagement based on the classroom video and audio recordings</td>\n",
              "      <td>Joyce</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1326191931</td>\n",
              "      <td>multimodal learning analytics in a laboratory classroom</td>\n",
              "      <td>Man Ching Esther Chan</td>\n",
              "      <td>2019</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO</td>\n",
              "      <td>POSE,GAZE,PROS</td>\n",
              "      <td>CLS,CLUST</td>\n",
              "      <td>LATE</td>\n",
              "      <td>MLPALA</td>\n",
              "      <td>Machine Learning Paradigms: Advances in Learning Analytics</td>\n",
              "      <td>3</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND, MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>MB</td>\n",
              "      <td>Within heavily rigged smart classroom, visual (gaze, posture) and auditory (speech levels) were extracted via AI and were then used (rule's based approach -&gt; model) to compute student's engagement in individual, pair, and group structures.</td>\n",
              "      <td>Eduardo</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1326191931</td>\n",
              "      <td>multimodal learning analytics in a laboratory classroom</td>\n",
              "      <td>Man Ching Esther Chan</td>\n",
              "      <td>2019</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO</td>\n",
              "      <td>POSE,GAZE,PROS</td>\n",
              "      <td>CLS,CLUST</td>\n",
              "      <td>LATE</td>\n",
              "      <td>MLPALA</td>\n",
              "      <td>Machine Learning Paradigms: Advances in Learning Analytics</td>\n",
              "      <td>3</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND, MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>MB</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Joyce/Eduardo</td>\n",
              "      <td>1&amp;2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1469065963</td>\n",
              "      <td>examining socially shared regulation and shared physiological arousal events with multimodal learning analytics</td>\n",
              "      <td>Andy Nguyen</td>\n",
              "      <td>2022</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO,SENSOR</td>\n",
              "      <td>QUAL,EDA</td>\n",
              "      <td>PATT,CLS,CLUST</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>BJET</td>\n",
              "      <td>British Journal of Educational Technology</td>\n",
              "      <td>4</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "      <td>Results indicate that physiological arousal could indicate engagement in metacognitive interactions, provided evidence for physiological activities as triggers for adaptive loops of learning regulation in collaborative learning. They utilised the CNN model to classify the sequences of regulatory activities and Shared Physiological Arousal Events moments and results have provided a proof of concept and indicated the potential of using ML for predicting collaborative learning success.</td>\n",
              "      <td>Joyce</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1469065963</td>\n",
              "      <td>examining socially shared regulation and shared physiological arousal events with multimodal learning analytics</td>\n",
              "      <td>Andy Nguyen</td>\n",
              "      <td>2022</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO,SENSOR</td>\n",
              "      <td>QUAL,EDA</td>\n",
              "      <td>PATT,CLS,CLUST</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>BJET</td>\n",
              "      <td>British Journal of Educational Technology</td>\n",
              "      <td>4</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "      <td>The paper explores the correlation of physiological signals to metacognition interactions in a collaborative setting. Two researchers video coded sessions into sequences of interactions. With these sequences, Markov chains were made and a 1D CNN (input physiological signal, output interaction label) was trained, with preliminary results that suggest a possible future direction.</td>\n",
              "      <td>Eduardo</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e47cede-64b8-4263-9e3b-e3dd9992f582')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2e47cede-64b8-4263-9e3b-e3dd9992f582 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2e47cede-64b8-4263-9e3b-e3dd9992f582');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9d2b28c9-b224-4205-a30d-7f18c8429c71\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d2b28c9-b224-4205-a30d-7f18c8429c71')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9d2b28c9-b224-4205-a30d-7f18c8429c71 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify S17 UUIDs match\n",
        "S17_PATH = \"drive/My Drive/Clayton/20230420_MMLTE/S17.csv\"\n",
        "df_17 = pd.read_csv(S17_PATH,header=0)\n",
        "assert set(df_17.UUID) == set(df.UUID)\n",
        "assert len(set(df_17.UUID)) == len(set(df.UUID)) == 73"
      ],
      "metadata": {
        "id": "sF_ZnHbdLFHG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partition DataFrame\n",
        "\n",
        "Create individual DataFrames for Clayton, Caleb, Eduardo, and Joyce."
      ],
      "metadata": {
        "id": "Lt5O81SDLlKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clayton = df.loc[df['Full-Read 3 by Researcher'] == \"Clayton\"]\n",
        "df_clayton.reset_index(drop=True,inplace=True)\n",
        "\n",
        "df_caleb = df.loc[df['Full-Read 3 by Researcher'] == \"Caleb\"]\n",
        "df_caleb.reset_index(drop=True,inplace=True)\n",
        "\n",
        "df_eduardo = df.loc[df['Full-Read 3 by Researcher'] == \"Eduardo\"]\n",
        "df_eduardo.reset_index(drop=True,inplace=True)\n",
        "\n",
        "df_joyce = df.loc[df['Full-Read 3 by Researcher'] == \"Joyce\"]\n",
        "df_joyce.reset_index(drop=True,inplace=True)\n",
        "\n",
        "assert len(df_clayton) + len(df_caleb) + len(df_eduardo) + len(df_joyce) == len(df) - 73\n",
        "assert len(df_clayton) == len(df_caleb) and len(df_eduardo) == len(df_joyce)\n",
        "assert set(df.UUID) ==  set(df_clayton.UUID).union(set(df_caleb.UUID)).union(set(df_eduardo.UUID).union(set(df_joyce.UUID)))\n",
        "assert len(set(df.UUID)) == len(set(df_clayton.UUID).union(set(df_caleb.UUID))) + \\\n",
        "      len(set(df_eduardo.UUID).union(set(df_joyce.UUID)))"
      ],
      "metadata": {
        "id": "w9eXQZqYLlcL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confirm orderings are correct for Cohen's *k*."
      ],
      "metadata": {
        "id": "dxtG69fVMpy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i,row in df_clayton.iterrows():\n",
        "  assert row['UUID'] == df_caleb.iloc[i]['UUID']\n",
        "\n",
        "for i,row in df_eduardo.iterrows():\n",
        "  assert row['UUID'] == df_joyce.iloc[i]['UUID']"
      ],
      "metadata": {
        "id": "bKFcNcbEMv36"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cohen's *k*"
      ],
      "metadata": {
        "id": "B6lz9DcHO7d3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_categories_cohens_k = {}"
      ],
      "metadata": {
        "id": "s1HIYS07Z8Cx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Setting"
      ],
      "metadata": {
        "id": "EZrmH_LWO_Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_setting_features = [\"BLND\",\"PHYS\",\"VIRT\",\"UNSP\"]"
      ],
      "metadata": {
        "id": "f3mHPi2WPBmg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from sklearn.metrics import cohen_kappa_score as cks\n",
        "\n",
        "# Clayton/Caleb score\n",
        "# Joyce/Eduardo score\n",
        "# Average between both pairs\n",
        "# Average of all features per category\n",
        "# Average of all categories\n",
        "\n",
        "env_setting_dict = {}\n",
        "\n",
        "for f in env_setting_features:\n",
        "\n",
        "  clayton_f_scores = []\n",
        "  for i,row in df_clayton.iterrows():\n",
        "    vals = set(row[\"Environment Setting\"].split(\", \"))\n",
        "    clayton_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  caleb_f_scores = []\n",
        "  for i,row in df_caleb.iterrows():\n",
        "    vals = set(row[\"Environment Setting\"].split(\", \"))\n",
        "    caleb_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  eduardo_f_scores = []\n",
        "  for i,row in df_eduardo.iterrows():\n",
        "    vals = set(row[\"Environment Setting\"].split(\", \"))\n",
        "    eduardo_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  joyce_f_scores = []\n",
        "  for i,row in df_joyce.iterrows():\n",
        "    vals = set(row[\"Environment Setting\"].split(\", \"))\n",
        "    joyce_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  clayton_caleb = cks(clayton_f_scores,caleb_f_scores)\n",
        "  eduardo_joyce = cks(joyce_f_scores,eduardo_f_scores)\n",
        "\n",
        "  avg = 0\n",
        "  if math.isnan(clayton_caleb):\n",
        "    avg = eduardo_joyce\n",
        "  elif math.isnan(eduardo_joyce):\n",
        "    avg = clayton_caleb\n",
        "  else:\n",
        "    avg = (clayton_caleb + eduardo_joyce) / 2\n",
        "\n",
        "  env_setting_dict[f] = avg\n",
        "\n",
        "env_setting_dict[\"TOTAL\"] = sum(env_setting_dict.values()) / len(env_setting_dict)\n",
        "env_setting_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctnKAVntQR-i",
        "outputId": "3803b4fd-82c9-424b-db08-19a4c635c7d3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BLND': 0.8643774703557312,\n",
              " 'PHYS': 0.8263377062289246,\n",
              " 'VIRT': 0.9433673321968274,\n",
              " 'UNSP': 0.6538461538461539,\n",
              " 'TOTAL': 0.8219821656569092}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_categories_cohens_k[\"Environment Setting\"] = env_setting_dict[\"TOTAL\"]\n",
        "all_categories_cohens_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "078PN9S3Z4HT",
        "outputId": "73eb14d5-72f5-4bce-d178-d8d2d077ac65"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Environment Setting': 0.8219821656569092}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Subject"
      ],
      "metadata": {
        "id": "IJoGeVazPBro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_subject_features = [\"HUM\",\"OTH\",\"PSY\",\"STEM\",\"UNSP\"]"
      ],
      "metadata": {
        "id": "tI8ebItLdBpC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_subject_dict = {}\n",
        "\n",
        "for f in env_subject_features:\n",
        "\n",
        "  clayton_f_scores = []\n",
        "  for i,row in df_clayton.iterrows():\n",
        "    vals = set(row[\"Environment Subject\"].split(\", \"))\n",
        "    clayton_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  caleb_f_scores = []\n",
        "  for i,row in df_caleb.iterrows():\n",
        "    vals = set(row[\"Environment Subject\"].split(\", \"))\n",
        "    caleb_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  eduardo_f_scores = []\n",
        "  for i,row in df_eduardo.iterrows():\n",
        "    vals = set(row[\"Environment Subject\"].split(\", \"))\n",
        "    eduardo_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  joyce_f_scores = []\n",
        "  for i,row in df_joyce.iterrows():\n",
        "    vals = set(row[\"Environment Subject\"].split(\", \"))\n",
        "    joyce_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  clayton_caleb = cks(clayton_f_scores,caleb_f_scores)\n",
        "  eduardo_joyce = cks(joyce_f_scores,eduardo_f_scores)\n",
        "\n",
        "  avg = 0\n",
        "  if math.isnan(clayton_caleb):\n",
        "    avg = eduardo_joyce\n",
        "  elif math.isnan(eduardo_joyce):\n",
        "    avg = clayton_caleb\n",
        "  else:\n",
        "    avg = (clayton_caleb + eduardo_joyce) / 2\n",
        "\n",
        "  env_subject_dict[f] = avg\n",
        "\n",
        "env_subject_dict[\"TOTAL\"] = sum(env_subject_dict.values()) / len(env_subject_dict)\n",
        "env_subject_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9beed4b1-19e0-455c-85de-0b091ddcc02f",
        "id": "PCBDajKDdBpD"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'HUM': 0.8833055972723951,\n",
              " 'OTH': 0.17215496368038735,\n",
              " 'PSY': 0.9368600682593857,\n",
              " 'STEM': 0.8300486223662884,\n",
              " 'UNSP': 0.8928571428571428,\n",
              " 'TOTAL': 0.7430452788871199}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_categories_cohens_k[\"Environment Subject\"] = env_subject_dict[\"TOTAL\"]\n",
        "all_categories_cohens_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdOljDuhdV__",
        "outputId": "e2cf89fd-306b-48da-af92-68895850efd9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Environment Setting': 0.8219821656569092,\n",
              " 'Environment Subject': 0.7430452788871199}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Participant Structure"
      ],
      "metadata": {
        "id": "83ARett9PDj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_participant_features = [\"IND\",\"MULTI\"]"
      ],
      "metadata": {
        "id": "p3eJnS4edxzL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_participant_dict = {}\n",
        "\n",
        "for f in env_participant_features:\n",
        "\n",
        "  clayton_f_scores = []\n",
        "  for i,row in df_clayton.iterrows():\n",
        "    vals = set(row[\"Participant Structure\"].split(\", \"))\n",
        "    clayton_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  caleb_f_scores = []\n",
        "  for i,row in df_caleb.iterrows():\n",
        "    vals = set(row[\"Participant Structure\"].split(\", \"))\n",
        "    caleb_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  eduardo_f_scores = []\n",
        "  for i,row in df_eduardo.iterrows():\n",
        "    vals = set(row[\"Participant Structure\"].split(\", \"))\n",
        "    eduardo_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  joyce_f_scores = []\n",
        "  for i,row in df_joyce.iterrows():\n",
        "    vals = set(row[\"Participant Structure\"].split(\", \"))\n",
        "    joyce_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  clayton_caleb = cks(clayton_f_scores,caleb_f_scores)\n",
        "  eduardo_joyce = cks(joyce_f_scores,eduardo_f_scores)\n",
        "\n",
        "  avg = 0\n",
        "  if math.isnan(clayton_caleb):\n",
        "    avg = eduardo_joyce\n",
        "  elif math.isnan(eduardo_joyce):\n",
        "    avg = clayton_caleb\n",
        "  else:\n",
        "    avg = (clayton_caleb + eduardo_joyce) / 2\n",
        "\n",
        "  env_participant_dict[f] = avg\n",
        "\n",
        "env_participant_dict[\"TOTAL\"] = sum(env_participant_dict.values()) / len(env_participant_dict)\n",
        "env_participant_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "126d72ae-9ea5-4708-bd20-5ebfa85afb71",
        "id": "ocOlD5-qdxzM"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'IND': 0.9187408491947291,\n",
              " 'MULTI': 0.9152941878505789,\n",
              " 'TOTAL': 0.917017518522654}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_categories_cohens_k[\"Participant Structure\"] = env_participant_dict[\"TOTAL\"]\n",
        "all_categories_cohens_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d03fad-c393-4a48-c755-a81280b8c1b1",
        "id": "B2SWvDG8dxzN"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Environment Setting': 0.8219821656569092,\n",
              " 'Environment Subject': 0.7430452788871199,\n",
              " 'Participant Structure': 0.917017518522654}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Didactic Nature"
      ],
      "metadata": {
        "id": "aSf9AqrnPFy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_didactic_features = [\"INF\",\"INSTR\",\"TRAIN\",\"UNSP\"]"
      ],
      "metadata": {
        "id": "peO87ldPeZ08"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_didactic_dict = {}\n",
        "\n",
        "for f in env_didactic_features:\n",
        "\n",
        "  clayton_f_scores = []\n",
        "  for i,row in df_clayton.iterrows():\n",
        "    vals = set(row[\"Didactic Nature\"].split(\", \"))\n",
        "    clayton_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  caleb_f_scores = []\n",
        "  for i,row in df_caleb.iterrows():\n",
        "    vals = set(row[\"Didactic Nature\"].split(\", \"))\n",
        "    caleb_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  eduardo_f_scores = []\n",
        "  for i,row in df_eduardo.iterrows():\n",
        "    vals = set(row[\"Didactic Nature\"].split(\", \"))\n",
        "    eduardo_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  joyce_f_scores = []\n",
        "  for i,row in df_joyce.iterrows():\n",
        "    vals = set(row[\"Didactic Nature\"].split(\", \"))\n",
        "    joyce_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  clayton_caleb = cks(clayton_f_scores,caleb_f_scores)\n",
        "  eduardo_joyce = cks(joyce_f_scores,eduardo_f_scores)\n",
        "\n",
        "  avg = 0\n",
        "  if math.isnan(clayton_caleb):\n",
        "    avg = eduardo_joyce\n",
        "  elif math.isnan(eduardo_joyce):\n",
        "    avg = clayton_caleb\n",
        "  else:\n",
        "    avg = (clayton_caleb + eduardo_joyce) / 2\n",
        "\n",
        "  env_didactic_dict[f] = avg\n",
        "\n",
        "env_didactic_dict[\"TOTAL\"] = sum(env_didactic_dict.values()) / len(env_didactic_dict)\n",
        "env_didactic_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca62c77-35bc-4f2d-a151-fcda5d8f06cc",
        "id": "MWc4hI-XeZ0-"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'INF': 0.4398744113029827,\n",
              " 'INSTR': 0.6278823778294902,\n",
              " 'TRAIN': 0.7304600132986763,\n",
              " 'UNSP': 0.4782608695652174,\n",
              " 'TOTAL': 0.5691194179990916}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_categories_cohens_k[\"Didactic Nature\"] = env_didactic_dict[\"TOTAL\"]\n",
        "all_categories_cohens_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef4045e1-6719-4830-c31d-d600c65438ee",
        "id": "aKT7CVNbeZ0-"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Environment Setting': 0.8219821656569092,\n",
              " 'Environment Subject': 0.7430452788871199,\n",
              " 'Participant Structure': 0.917017518522654,\n",
              " 'Didactic Nature': 0.5691194179990916}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Level of Instruction or Training"
      ],
      "metadata": {
        "id": "uETS7zDDPIMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_level_features = [\"UNI\",\"K12\",\"PROF\",\"UNSP\"]"
      ],
      "metadata": {
        "id": "WgoQb4z_hKja"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_level_dict = {}\n",
        "\n",
        "for f in env_level_features:\n",
        "\n",
        "  clayton_f_scores = []\n",
        "  for i,row in df_clayton.iterrows():\n",
        "    vals = set(row[\"Level of Instruction or Training\"].split(\", \"))\n",
        "    clayton_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  caleb_f_scores = []\n",
        "  for i,row in df_caleb.iterrows():\n",
        "    vals = set(row[\"Level of Instruction or Training\"].split(\", \"))\n",
        "    caleb_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  eduardo_f_scores = []\n",
        "  for i,row in df_eduardo.iterrows():\n",
        "    vals = set(row[\"Level of Instruction or Training\"].split(\", \"))\n",
        "    eduardo_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  joyce_f_scores = []\n",
        "  for i,row in df_joyce.iterrows():\n",
        "    vals = set(row[\"Level of Instruction or Training\"].split(\", \"))\n",
        "    joyce_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  clayton_caleb = cks(clayton_f_scores,caleb_f_scores)\n",
        "  eduardo_joyce = cks(joyce_f_scores,eduardo_f_scores)\n",
        "\n",
        "  avg = 0\n",
        "  if math.isnan(clayton_caleb):\n",
        "    avg = eduardo_joyce\n",
        "  elif math.isnan(eduardo_joyce):\n",
        "    avg = clayton_caleb\n",
        "  else:\n",
        "    avg = (clayton_caleb + eduardo_joyce) / 2\n",
        "\n",
        "  env_level_dict[f] = avg\n",
        "\n",
        "env_level_dict[\"TOTAL\"] = sum(env_level_dict.values()) / len(env_level_dict)\n",
        "env_level_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7057b82b-b946-45d4-a87a-826005e2fe37",
        "id": "adI2F4JbhKjc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'UNI': 0.8300442081539484,\n",
              " 'K12': 0.972913616398243,\n",
              " 'PROF': 0.6372549019607843,\n",
              " 'UNSP': 0.6372549019607843,\n",
              " 'TOTAL': 0.76936690711844}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_categories_cohens_k[\"Level of Instruction or Training\"] = env_level_dict[\"TOTAL\"]\n",
        "all_categories_cohens_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7cdcb59-8346-47b5-f666-b88740df8c5b",
        "id": "FTdc16F9hKjd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Environment Setting': 0.8219821656569092,\n",
              " 'Environment Subject': 0.7430452788871199,\n",
              " 'Participant Structure': 0.917017518522654,\n",
              " 'Didactic Nature': 0.5691194179990916,\n",
              " 'Level of Instruction or Training': 0.76936690711844}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis Approach"
      ],
      "metadata": {
        "id": "IDsDin3QPLtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_analysis_features = [\"MB\",\"MF\"]"
      ],
      "metadata": {
        "id": "4ryB8v1Iif-g"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_analysis_dict = {}\n",
        "\n",
        "for f in env_analysis_features:\n",
        "\n",
        "  clayton_f_scores = []\n",
        "  for i,row in df_clayton.iterrows():\n",
        "    vals = set(row[\"Analysis Approach\"].split(\", \"))\n",
        "    clayton_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  caleb_f_scores = []\n",
        "  for i,row in df_caleb.iterrows():\n",
        "    vals = set(row[\"Analysis Approach\"].split(\", \"))\n",
        "    caleb_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  eduardo_f_scores = []\n",
        "  for i,row in df_eduardo.iterrows():\n",
        "    vals = set(row[\"Analysis Approach\"].split(\", \"))\n",
        "    eduardo_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  joyce_f_scores = []\n",
        "  for i,row in df_joyce.iterrows():\n",
        "    vals = set(row[\"Analysis Approach\"].split(\", \"))\n",
        "    joyce_f_scores.append(1 if f in vals else 0)\n",
        "\n",
        "  clayton_caleb = cks(clayton_f_scores,caleb_f_scores)\n",
        "  eduardo_joyce = cks(joyce_f_scores,eduardo_f_scores)\n",
        "\n",
        "  avg = 0\n",
        "  if math.isnan(clayton_caleb):\n",
        "    avg = eduardo_joyce\n",
        "  elif math.isnan(eduardo_joyce):\n",
        "    avg = clayton_caleb\n",
        "  else:\n",
        "    avg = (clayton_caleb + eduardo_joyce) / 2\n",
        "\n",
        "  env_analysis_dict[f] = avg\n",
        "\n",
        "env_analysis_dict[\"TOTAL\"] = sum(env_analysis_dict.values()) / len(env_analysis_dict)\n",
        "env_analysis_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b95f777-0631-4bd8-e15e-cbfbe62ba4e0",
        "id": "I0DieW38if-h"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MB': 0.4303054879697215,\n",
              " 'MF': 0.45092296769613066,\n",
              " 'TOTAL': 0.4406142278329261}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_categories_cohens_k[\"Analysis Approach\"] = env_analysis_dict[\"TOTAL\"]\n",
        "all_categories_cohens_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5384f9-0634-4a57-90f8-186110340d39",
        "id": "rBZJP8r_if-h"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Environment Setting': 0.8219821656569092,\n",
              " 'Environment Subject': 0.7430452788871199,\n",
              " 'Participant Structure': 0.917017518522654,\n",
              " 'Didactic Nature': 0.5691194179990916,\n",
              " 'Level of Instruction or Training': 0.76936690711844,\n",
              " 'Analysis Approach': 0.4406142278329261}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aggregated"
      ],
      "metadata": {
        "id": "-laD3V7UPQpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = sum(all_categories_cohens_k.values()) / len(all_categories_cohens_k)\n",
        "k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3Er0gTKPRtc",
        "outputId": "7b16f87d-bd66-47dd-a27c-deb944931040"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7101909193361902"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final S18 Spreadsheet"
      ],
      "metadata": {
        "id": "ydwOX7sWiPD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create consensus sheet\n",
        "\n",
        "df_consensus = df[df['Reviewer'] == \"1&2\"]\n",
        "df_consensus.reset_index(inplace=True,drop=True)\n",
        "df_consensus.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "id": "Geu6BQh2iTLH",
        "outputId": "966a7c5c-3606-4753-a165-cb4eaa4b6ba4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         UUID  \\\n",
              "0  1326191931   \n",
              "1  1469065963   \n",
              "2  1598166515   \n",
              "3  1877483551   \n",
              "4  2000036002   \n",
              "\n",
              "                                                                                                             Title  \\\n",
              "0                                                          multimodal learning analytics in a laboratory classroom   \n",
              "1  examining socially shared regulation and shared physiological arousal events with multimodal learning analytics   \n",
              "2                                                            multimodal learning analytics for game-based learning   \n",
              "3                           motion-based educational games: using multi-modal data to predict players performance   \n",
              "4                            predicting learners effortful behaviour in adaptive assessment using multimodal data   \n",
              "\n",
              "     Mapped First Author  Year Environment Type (learning or training)  \\\n",
              "0  Man Ching Esther Chan  2019                                Learning   \n",
              "1            Andy Nguyen  2022                                Learning   \n",
              "2         Andrew Emerson  2020                                Learning   \n",
              "3     Serena Lee-Cultura  2020                                Learning   \n",
              "4         Kshitij Sharma  2020                                Learning   \n",
              "\n",
              "  Mapped Data Collection Mediums               Mapped Modalities  \\\n",
              "0                    VIDEO,AUDIO                  POSE,GAZE,PROS   \n",
              "1             VIDEO,AUDIO,SENSOR                        QUAL,EDA   \n",
              "2                 VIDEO,LOGS,EYE            AFFECT,GAZE,LOGS,PPA   \n",
              "3               VIDEO,EYE,SENSOR        PULSE,TEMP,EDA,GAZE,POSE   \n",
              "4               VIDEO,EYE,SENSOR  EDA,TEMP,PULSE,EEG,GAZE,AFFECT   \n",
              "\n",
              "  Mapped Analysis Methods Mapped Fusion Types Mapped Publication Acronym  \\\n",
              "0               CLS,CLUST                LATE                     MLPALA   \n",
              "1          PATT,CLS,CLUST              HYBRID                       BJET   \n",
              "2               CLS,STATS                 MID                       BJET   \n",
              "3                     CLS                 MID                        COG   \n",
              "4          CLUST,CLS,PATT                 MID                        LAK   \n",
              "\n",
              "                                      Mapped Full Publication  Sort Number  \\\n",
              "0  Machine Learning Paradigms: Advances in Learning Analytics            3   \n",
              "1                   British Journal of Educational Technology            4   \n",
              "2                   British Journal of Educational Technology            5   \n",
              "3                                    IEEE Conference on Games            6   \n",
              "4  International Conference on Learning Analytics & Knowledge            7   \n",
              "\n",
              "  Environment Setting Environment Subject Participant Structure  \\\n",
              "0                PHYS                STEM            IND, MULTI   \n",
              "1                PHYS                STEM                 MULTI   \n",
              "2                VIRT                STEM                   IND   \n",
              "3                BLND                STEM                   IND   \n",
              "4                VIRT                STEM                   IND   \n",
              "\n",
              "  Didactic Nature Level of Instruction or Training Analysis Approach  \\\n",
              "0           INSTR                             UNSP                MB   \n",
              "1           INSTR                              K12                MB   \n",
              "2             INF                              UNI                MB   \n",
              "3           INSTR                              K12                MB   \n",
              "4           INSTR                              UNI                MB   \n",
              "\n",
              "  Analysis Results (w/ multimodal advantages) Full-Read 3 by Researcher  \\\n",
              "0                                         NaN             Joyce/Eduardo   \n",
              "1                                         NaN             Joyce/Eduardo   \n",
              "2                                         NaN             Joyce/Eduardo   \n",
              "3                                         NaN             Joyce/Eduardo   \n",
              "4                                         NaN             Joyce/Eduardo   \n",
              "\n",
              "  Reviewer Reviewer Notes  \n",
              "0      1&2            NaN  \n",
              "1      1&2            NaN  \n",
              "2      1&2            NaN  \n",
              "3      1&2            NaN  \n",
              "4      1&2            NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-038f0cc6-96de-416f-8498-e694ca986755\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UUID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Mapped First Author</th>\n",
              "      <th>Year</th>\n",
              "      <th>Environment Type (learning or training)</th>\n",
              "      <th>Mapped Data Collection Mediums</th>\n",
              "      <th>Mapped Modalities</th>\n",
              "      <th>Mapped Analysis Methods</th>\n",
              "      <th>Mapped Fusion Types</th>\n",
              "      <th>Mapped Publication Acronym</th>\n",
              "      <th>Mapped Full Publication</th>\n",
              "      <th>Sort Number</th>\n",
              "      <th>Environment Setting</th>\n",
              "      <th>Environment Subject</th>\n",
              "      <th>Participant Structure</th>\n",
              "      <th>Didactic Nature</th>\n",
              "      <th>Level of Instruction or Training</th>\n",
              "      <th>Analysis Approach</th>\n",
              "      <th>Analysis Results (w/ multimodal advantages)</th>\n",
              "      <th>Full-Read 3 by Researcher</th>\n",
              "      <th>Reviewer</th>\n",
              "      <th>Reviewer Notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1326191931</td>\n",
              "      <td>multimodal learning analytics in a laboratory classroom</td>\n",
              "      <td>Man Ching Esther Chan</td>\n",
              "      <td>2019</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO</td>\n",
              "      <td>POSE,GAZE,PROS</td>\n",
              "      <td>CLS,CLUST</td>\n",
              "      <td>LATE</td>\n",
              "      <td>MLPALA</td>\n",
              "      <td>Machine Learning Paradigms: Advances in Learning Analytics</td>\n",
              "      <td>3</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND, MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>MB</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Joyce/Eduardo</td>\n",
              "      <td>1&amp;2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1469065963</td>\n",
              "      <td>examining socially shared regulation and shared physiological arousal events with multimodal learning analytics</td>\n",
              "      <td>Andy Nguyen</td>\n",
              "      <td>2022</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO,SENSOR</td>\n",
              "      <td>QUAL,EDA</td>\n",
              "      <td>PATT,CLS,CLUST</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>BJET</td>\n",
              "      <td>British Journal of Educational Technology</td>\n",
              "      <td>4</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Joyce/Eduardo</td>\n",
              "      <td>1&amp;2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1598166515</td>\n",
              "      <td>multimodal learning analytics for game-based learning</td>\n",
              "      <td>Andrew Emerson</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,LOGS,EYE</td>\n",
              "      <td>AFFECT,GAZE,LOGS,PPA</td>\n",
              "      <td>CLS,STATS</td>\n",
              "      <td>MID</td>\n",
              "      <td>BJET</td>\n",
              "      <td>British Journal of Educational Technology</td>\n",
              "      <td>5</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INF</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Joyce/Eduardo</td>\n",
              "      <td>1&amp;2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1877483551</td>\n",
              "      <td>motion-based educational games: using multi-modal data to predict players performance</td>\n",
              "      <td>Serena Lee-Cultura</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,EYE,SENSOR</td>\n",
              "      <td>PULSE,TEMP,EDA,GAZE,POSE</td>\n",
              "      <td>CLS</td>\n",
              "      <td>MID</td>\n",
              "      <td>COG</td>\n",
              "      <td>IEEE Conference on Games</td>\n",
              "      <td>6</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Joyce/Eduardo</td>\n",
              "      <td>1&amp;2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000036002</td>\n",
              "      <td>predicting learners effortful behaviour in adaptive assessment using multimodal data</td>\n",
              "      <td>Kshitij Sharma</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,EYE,SENSOR</td>\n",
              "      <td>EDA,TEMP,PULSE,EEG,GAZE,AFFECT</td>\n",
              "      <td>CLUST,CLS,PATT</td>\n",
              "      <td>MID</td>\n",
              "      <td>LAK</td>\n",
              "      <td>International Conference on Learning Analytics &amp; Knowledge</td>\n",
              "      <td>7</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Joyce/Eduardo</td>\n",
              "      <td>1&amp;2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-038f0cc6-96de-416f-8498-e694ca986755')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-038f0cc6-96de-416f-8498-e694ca986755 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-038f0cc6-96de-416f-8498-e694ca986755');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2a440299-3e05-4044-abd1-cbe8bd5803f9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a440299-3e05-4044-abd1-cbe8bd5803f9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2a440299-3e05-4044-abd1-cbe8bd5803f9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_consensus.sort_values([\"Year\",\"Mapped First Author\", \"UUID\"], inplace=True, ascending=True)\n",
        "df_consensus.drop(columns=[\"Mapped Full Publication\", \\\n",
        "                           \"Sort Number\", \\\n",
        "                           \"Analysis Results (w/ multimodal advantages)\", \\\n",
        "                           \"Full-Read 3 by Researcher\", \\\n",
        "                           \"Reviewer\", \\\n",
        "                           \"Reviewer Notes\"],\n",
        "                  inplace=True)\n",
        "df_consensus.reset_index(inplace=True,drop=True)\n",
        "df_consensus.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SZJ34o_TroQ1",
        "outputId": "7c279687-9881-442d-8b53-43096327ff57"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-b30b5dfa91e6>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_consensus.sort_values([\"Year\",\"Mapped First Author\", \"UUID\"], inplace=True, ascending=True)\n",
            "<ipython-input-28-b30b5dfa91e6>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_consensus.drop(columns=[\"Mapped Full Publication\", \\\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         UUID  \\\n",
              "0   818492192   \n",
              "1  3408664396   \n",
              "2  1118315889   \n",
              "3  3339002981   \n",
              "4  1609706685   \n",
              "\n",
              "                                                                                                                                 Title  \\\n",
              "0  understanding student learning trajectories using multimodal learning analytics within an embodied-interaction learning environment   \n",
              "1                                                                         multimodal student engagement recognition in prosocial games   \n",
              "2                                   using multimodal learning analytics to identify aspects of collaboration in project-based learning   \n",
              "3                                      estimation of success in collaborative learning based on multimodal learning analytics features   \n",
              "4              learning pulse: a machine learning approach for predicting performance in self-regulated learning using multimodal data   \n",
              "\n",
              "  Mapped First Author  Year Environment Type (learning or training)  \\\n",
              "0   Alejandro Andrade  2017                                Learning   \n",
              "1  Athanasios Psaltis  2017                                Learning   \n",
              "2       Daniel Spikol  2017                                Learning   \n",
              "3       Daniel Spikol  2017                                Learning   \n",
              "4    Daniele Di Mitri  2017                                Training   \n",
              "\n",
              "  Mapped Data Collection Mediums         Mapped Modalities  \\\n",
              "0           VIDEO,LOGS,INTER,PPA  GAZE,LOGS,INTER,PPA,GEST   \n",
              "1                     VIDEO,LOGS          POSE,AFFECT,LOGS   \n",
              "2               VIDEO,AUDIO,LOGS                 POSE,PROS   \n",
              "3           EYE,LOGS,VIDEO,AUDIO       GAZE,LOGS,PROS,POSE   \n",
              "4         SENSOR,LOGS,MOTION,PPA          PULSE,ACT,AFFECT   \n",
              "\n",
              "  Mapped Analysis Methods Mapped Fusion Types Mapped Publication Acronym  \\\n",
              "0              CLUST,QUAL              HYBRID                        LAK   \n",
              "1                     CLS                LATE                    T-CIAIG   \n",
              "2                     REG                 MID                       CSCL   \n",
              "3                     CLS                 MID                      ICALT   \n",
              "4                     REG                 MID                        LAK   \n",
              "\n",
              "  Environment Setting Environment Subject Participant Structure  \\\n",
              "0                BLND                STEM                   IND   \n",
              "1                BLND                 HUM                   IND   \n",
              "2                PHYS                STEM                 MULTI   \n",
              "3                VIRT                STEM                 MULTI   \n",
              "4                BLND                UNSP                   IND   \n",
              "\n",
              "  Didactic Nature Level of Instruction or Training Analysis Approach  \n",
              "0           INSTR                              K12                MB  \n",
              "1             INF                              K12                MB  \n",
              "2           INSTR                              UNI                MB  \n",
              "3           INSTR                              UNI                MB  \n",
              "4            UNSP                              UNI                MB  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5204202-c459-4b83-9ab9-44963417524b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UUID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Mapped First Author</th>\n",
              "      <th>Year</th>\n",
              "      <th>Environment Type (learning or training)</th>\n",
              "      <th>Mapped Data Collection Mediums</th>\n",
              "      <th>Mapped Modalities</th>\n",
              "      <th>Mapped Analysis Methods</th>\n",
              "      <th>Mapped Fusion Types</th>\n",
              "      <th>Mapped Publication Acronym</th>\n",
              "      <th>Environment Setting</th>\n",
              "      <th>Environment Subject</th>\n",
              "      <th>Participant Structure</th>\n",
              "      <th>Didactic Nature</th>\n",
              "      <th>Level of Instruction or Training</th>\n",
              "      <th>Analysis Approach</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>818492192</td>\n",
              "      <td>understanding student learning trajectories using multimodal learning analytics within an embodied-interaction learning environment</td>\n",
              "      <td>Alejandro Andrade</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,LOGS,INTER,PPA</td>\n",
              "      <td>GAZE,LOGS,INTER,PPA,GEST</td>\n",
              "      <td>CLUST,QUAL</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>LAK</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3408664396</td>\n",
              "      <td>multimodal student engagement recognition in prosocial games</td>\n",
              "      <td>Athanasios Psaltis</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,LOGS</td>\n",
              "      <td>POSE,AFFECT,LOGS</td>\n",
              "      <td>CLS</td>\n",
              "      <td>LATE</td>\n",
              "      <td>T-CIAIG</td>\n",
              "      <td>BLND</td>\n",
              "      <td>HUM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INF</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1118315889</td>\n",
              "      <td>using multimodal learning analytics to identify aspects of collaboration in project-based learning</td>\n",
              "      <td>Daniel Spikol</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO,LOGS</td>\n",
              "      <td>POSE,PROS</td>\n",
              "      <td>REG</td>\n",
              "      <td>MID</td>\n",
              "      <td>CSCL</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3339002981</td>\n",
              "      <td>estimation of success in collaborative learning based on multimodal learning analytics features</td>\n",
              "      <td>Daniel Spikol</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning</td>\n",
              "      <td>EYE,LOGS,VIDEO,AUDIO</td>\n",
              "      <td>GAZE,LOGS,PROS,POSE</td>\n",
              "      <td>CLS</td>\n",
              "      <td>MID</td>\n",
              "      <td>ICALT</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1609706685</td>\n",
              "      <td>learning pulse: a machine learning approach for predicting performance in self-regulated learning using multimodal data</td>\n",
              "      <td>Daniele Di Mitri</td>\n",
              "      <td>2017</td>\n",
              "      <td>Training</td>\n",
              "      <td>SENSOR,LOGS,MOTION,PPA</td>\n",
              "      <td>PULSE,ACT,AFFECT</td>\n",
              "      <td>REG</td>\n",
              "      <td>MID</td>\n",
              "      <td>LAK</td>\n",
              "      <td>BLND</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>IND</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5204202-c459-4b83-9ab9-44963417524b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a5204202-c459-4b83-9ab9-44963417524b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a5204202-c459-4b83-9ab9-44963417524b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-74db549c-d375-4670-9840-c9e3f25460a3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74db549c-d375-4670-9840-c9e3f25460a3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-74db549c-d375-4670-9840-c9e3f25460a3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map columns\n",
        "df_consensus.rename(columns={\n",
        "    'Mapped First Author': 'First Author',\n",
        "    'Environment Type (learning or training)': 'Environment Type', \\\n",
        "    'Mapped Data Collection Mediums':'Data Collection Mediums', \\\n",
        "    'Mapped Modalities' : 'Modalities', \\\n",
        "    'Mapped Analysis Methods' : 'Analysis Methods', \\\n",
        "    'Mapped Fusion Types' : 'Fusion Types', \\\n",
        "    'Mapped Publication Acronym' : 'Publication'}, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhJLpg9xy_tJ",
        "outputId": "1b8109c5-28d0-49c2-fefa-0d86bbdb1f8b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-88a35afcc3e2>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_consensus.rename(columns={\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert not df_consensus.isnull().values.any()\n",
        "assert len(df_consensus) == 73\n",
        "assert len(set(df_consensus.UUID)) == 73\n",
        "assert set(df_consensus.UUID) == set(df.UUID)"
      ],
      "metadata": {
        "id": "tJJrawa9rdhN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare to S17 to verify."
      ],
      "metadata": {
        "id": "FtMeNgRErk1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_17.sort_values([\"Year\",\"Mapped First Author\", \"UUID\"], inplace=True, ascending=True)\n",
        "df_17.reset_index(inplace=True,drop=True)\n",
        "df_17.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e9RNffm8tifx",
        "outputId": "84ec9338-f3f9-4bb8-920e-0734839798e0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         UUID  \\\n",
              "0   818492192   \n",
              "1  3408664396   \n",
              "2  1118315889   \n",
              "3  3339002981   \n",
              "4  1609706685   \n",
              "\n",
              "                                                                                                                                 Title  \\\n",
              "0  understanding student learning trajectories using multimodal learning analytics within an embodied-interaction learning environment   \n",
              "1                                                                         multimodal student engagement recognition in prosocial games   \n",
              "2                                   using multimodal learning analytics to identify aspects of collaboration in project-based learning   \n",
              "3                                      estimation of success in collaborative learning based on multimodal learning analytics features   \n",
              "4              learning pulse: a machine learning approach for predicting performance in self-regulated learning using multimodal data   \n",
              "\n",
              "  Mapped First Author  Year Environment Type (learning or training)  \\\n",
              "0   Alejandro Andrade  2017                                Learning   \n",
              "1  Athanasios Psaltis  2017                                Learning   \n",
              "2       Daniel Spikol  2017                                Learning   \n",
              "3       Daniel Spikol  2017                                Learning   \n",
              "4    Daniele Di Mitri  2017                                Training   \n",
              "\n",
              "  Mapped Data Collection Mediums         Mapped Modalities  \\\n",
              "0           VIDEO,LOGS,INTER,PPA  GAZE,LOGS,INTER,PPA,GEST   \n",
              "1                     VIDEO,LOGS          POSE,AFFECT,LOGS   \n",
              "2               VIDEO,AUDIO,LOGS                 POSE,PROS   \n",
              "3           EYE,LOGS,VIDEO,AUDIO       GAZE,LOGS,PROS,POSE   \n",
              "4         SENSOR,LOGS,MOTION,PPA          PULSE,ACT,AFFECT   \n",
              "\n",
              "  Mapped Analysis Methods Mapped Fusion Types Mapped Publication Acronym  \\\n",
              "0              CLUST,QUAL              HYBRID                        LAK   \n",
              "1                     CLS                LATE                    T-CIAIG   \n",
              "2                     REG                 MID                       CSCL   \n",
              "3                     CLS                 MID                      ICALT   \n",
              "4                     REG                 MID                        LAK   \n",
              "\n",
              "                                      Mapped Full Publication  \\\n",
              "0  International Conference on Learning Analytics & Knowledge   \n",
              "1  Transactions on Computational Intelligence and AI in Games   \n",
              "2     Conference on Computer Supported Collaborative Learning   \n",
              "3  International Conference on Advanced Learning Technologies   \n",
              "4  International Conference on Learning Analytics & Knowledge   \n",
              "\n",
              "  Full-Read 2 by Researcher  Reviewer Number  Sort Number  \n",
              "0             Caleb/Clayton                3           23  \n",
              "1             Joyce/Eduardo                3           15  \n",
              "2             Caleb/Clayton                3           26  \n",
              "3             Eduardo/Joyce                3           14  \n",
              "4             Eduardo/Joyce                3           69  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3612d39-13d7-420a-a84a-e67975f4990f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UUID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Mapped First Author</th>\n",
              "      <th>Year</th>\n",
              "      <th>Environment Type (learning or training)</th>\n",
              "      <th>Mapped Data Collection Mediums</th>\n",
              "      <th>Mapped Modalities</th>\n",
              "      <th>Mapped Analysis Methods</th>\n",
              "      <th>Mapped Fusion Types</th>\n",
              "      <th>Mapped Publication Acronym</th>\n",
              "      <th>Mapped Full Publication</th>\n",
              "      <th>Full-Read 2 by Researcher</th>\n",
              "      <th>Reviewer Number</th>\n",
              "      <th>Sort Number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>818492192</td>\n",
              "      <td>understanding student learning trajectories using multimodal learning analytics within an embodied-interaction learning environment</td>\n",
              "      <td>Alejandro Andrade</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,LOGS,INTER,PPA</td>\n",
              "      <td>GAZE,LOGS,INTER,PPA,GEST</td>\n",
              "      <td>CLUST,QUAL</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>LAK</td>\n",
              "      <td>International Conference on Learning Analytics &amp; Knowledge</td>\n",
              "      <td>Caleb/Clayton</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3408664396</td>\n",
              "      <td>multimodal student engagement recognition in prosocial games</td>\n",
              "      <td>Athanasios Psaltis</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,LOGS</td>\n",
              "      <td>POSE,AFFECT,LOGS</td>\n",
              "      <td>CLS</td>\n",
              "      <td>LATE</td>\n",
              "      <td>T-CIAIG</td>\n",
              "      <td>Transactions on Computational Intelligence and AI in Games</td>\n",
              "      <td>Joyce/Eduardo</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1118315889</td>\n",
              "      <td>using multimodal learning analytics to identify aspects of collaboration in project-based learning</td>\n",
              "      <td>Daniel Spikol</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO,LOGS</td>\n",
              "      <td>POSE,PROS</td>\n",
              "      <td>REG</td>\n",
              "      <td>MID</td>\n",
              "      <td>CSCL</td>\n",
              "      <td>Conference on Computer Supported Collaborative Learning</td>\n",
              "      <td>Caleb/Clayton</td>\n",
              "      <td>3</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3339002981</td>\n",
              "      <td>estimation of success in collaborative learning based on multimodal learning analytics features</td>\n",
              "      <td>Daniel Spikol</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning</td>\n",
              "      <td>EYE,LOGS,VIDEO,AUDIO</td>\n",
              "      <td>GAZE,LOGS,PROS,POSE</td>\n",
              "      <td>CLS</td>\n",
              "      <td>MID</td>\n",
              "      <td>ICALT</td>\n",
              "      <td>International Conference on Advanced Learning Technologies</td>\n",
              "      <td>Eduardo/Joyce</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1609706685</td>\n",
              "      <td>learning pulse: a machine learning approach for predicting performance in self-regulated learning using multimodal data</td>\n",
              "      <td>Daniele Di Mitri</td>\n",
              "      <td>2017</td>\n",
              "      <td>Training</td>\n",
              "      <td>SENSOR,LOGS,MOTION,PPA</td>\n",
              "      <td>PULSE,ACT,AFFECT</td>\n",
              "      <td>REG</td>\n",
              "      <td>MID</td>\n",
              "      <td>LAK</td>\n",
              "      <td>International Conference on Learning Analytics &amp; Knowledge</td>\n",
              "      <td>Eduardo/Joyce</td>\n",
              "      <td>3</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3612d39-13d7-420a-a84a-e67975f4990f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3612d39-13d7-420a-a84a-e67975f4990f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3612d39-13d7-420a-a84a-e67975f4990f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2cbba179-3185-4cfe-8820-2f04abca9654\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2cbba179-3185-4cfe-8820-2f04abca9654')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2cbba179-3185-4cfe-8820-2f04abca9654 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert df_17.UUID.equals(df_consensus.UUID)"
      ],
      "metadata": {
        "id": "LUV6yBZmvJw3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save consensus spreadsheet\n",
        "S18_PATH = \"drive/My Drive/Clayton/20230420_MMLTE/S18.csv\"\n",
        "df_consensus.to_csv(S18_PATH,index=False)"
      ],
      "metadata": {
        "id": "NpoHBBIkvzgD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify saved consensus\n",
        "df_import = pd.read_csv(S18_PATH)\n",
        "df_import.compare(df_consensus)\n",
        "assert df_import.equals(df_consensus)"
      ],
      "metadata": {
        "id": "XQRdp0rZv7T_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_consensus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w4EBGVwC0Z0H",
        "outputId": "b8e22e0b-c24a-4b0a-b85d-febe08d805df"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          UUID  \\\n",
              "0    818492192   \n",
              "1   3408664396   \n",
              "2   1118315889   \n",
              "3   3339002981   \n",
              "4   1609706685   \n",
              "5   3093310941   \n",
              "6   3095923626   \n",
              "7   2456887548   \n",
              "8   1374035721   \n",
              "9     85990093   \n",
              "10   957160695   \n",
              "11  1637690235   \n",
              "12  1886134458   \n",
              "13  2181637610   \n",
              "14   483140962   \n",
              "15  3146393211   \n",
              "16  3308658121   \n",
              "17  3135645357   \n",
              "18  3309250332   \n",
              "19  2836996318   \n",
              "20  3783339081   \n",
              "21  3796180663   \n",
              "22  2345021698   \n",
              "23   804659204   \n",
              "24  2497456347   \n",
              "25  2070224207   \n",
              "26  4019205162   \n",
              "27  1847468084   \n",
              "28  1326191931   \n",
              "29  4278392816   \n",
              "30  1576545447   \n",
              "31   853680639   \n",
              "32  3398902089   \n",
              "33    86191824   \n",
              "34  3448122334   \n",
              "35  1296637108   \n",
              "36  1019093033   \n",
              "37  1581261659   \n",
              "38  1598166515   \n",
              "39   205660768   \n",
              "40  3009548670   \n",
              "41  1770989706   \n",
              "42  3051560548   \n",
              "43   147203129   \n",
              "44  2000036002   \n",
              "45  2055153191   \n",
              "46  3796643912   \n",
              "47  2879332689   \n",
              "48  1877483551   \n",
              "49  3637456466   \n",
              "50  2936220551   \n",
              "51  2634033325   \n",
              "52   123412197   \n",
              "53  3809293172   \n",
              "54  1763513559   \n",
              "55  4035649049   \n",
              "56  3625722965   \n",
              "57  1426267857   \n",
              "58   666050348   \n",
              "59   518268671   \n",
              "60  3660066725   \n",
              "61  3856280479   \n",
              "62  4277812050   \n",
              "63   566043228   \n",
              "64  1315379489   \n",
              "65  1469065963   \n",
              "66   433919853   \n",
              "67  2273914836   \n",
              "68    32184286   \n",
              "69  2609260641   \n",
              "70  1345598079   \n",
              "71  2155422499   \n",
              "72  3754172825   \n",
              "\n",
              "                                                                                                                                                         Title  \\\n",
              "0                          understanding student learning trajectories using multimodal learning analytics within an embodied-interaction learning environment   \n",
              "1                                                                                                 multimodal student engagement recognition in prosocial games   \n",
              "2                                                           using multimodal learning analytics to identify aspects of collaboration in project-based learning   \n",
              "3                                                              estimation of success in collaborative learning based on multimodal learning analytics features   \n",
              "4                                      learning pulse: a machine learning approach for predicting performance in self-regulated learning using multimodal data   \n",
              "5                                      embodied conversational agents for multimodal automated social skills training in people with autism spectrum disorders   \n",
              "6                                                                                                                              a multimodal analysis of making   \n",
              "7                                                                       an unobtrusive and multimodal approach for behavioral engagement detection of students   \n",
              "8                                                                       attentivelearner2: a multimodal approach for improving mooc learning on mobile devices   \n",
              "9                                                                                   multimodal markers of persuasive speech : designing a virtual debate coach   \n",
              "10                                                                                 virtual debate coach design: assessing multimodal argumentation performance   \n",
              "11                                               supervised machine learning in multimodal learning analytics for estimating success in project-based learning   \n",
              "12                                                                        personalizing computer science education by leveraging multimodal learning analytics   \n",
              "13                                                        toward using multi-modal learning analytics to support and measure collaboration in co-located dyads   \n",
              "14                                                           investigating multimodal affect sensing in an affective tutoring system using unobtrusive sensors   \n",
              "15                                                      mobile mixed reality for experiential learning and simulation in medical and health sciences education   \n",
              "16                                                                             exploring collaboration using motion sensors and multi-modal learning analytics   \n",
              "17                                                       multimodal teaching analytics: automated extraction of orchestration graphs from wearable sensor data   \n",
              "18                                                      (dis)engagement matters: identifying efficacious learning practices with multimodal learning analytics   \n",
              "19                                                                    predicting learners' emotions in mobile mooc learning via a multimodal intelligent tutor   \n",
              "20                                        a novel method for the in-depth multimodal analysis of student learning trajectories in intelligent tutoring systems   \n",
              "21                                                                           learning linkages: integrating data streams of multiple modalities and timescales   \n",
              "22                           exploring collaborative writing of user stories with multimodal learning analytics: a case study on a software engineering course   \n",
              "23                                                                          towards smart educational recommendations with reinforcement learning in classroom   \n",
              "24                                               the rap system: automatic feedback of oral presentation skills using multimodal analysis and low-cost sensors   \n",
              "25                                                                               detecting medical simulation errors with machine learning and multimodal data   \n",
              "26                    introducing low-cost sensors into the classroom settings: improving the assessment in agile practices with multimodal learning analytics   \n",
              "27                                                                        computationally augmented ethnography: emotion tracking and learning in museum games   \n",
              "28                                                                                                     multimodal learning analytics in a laboratory classroom   \n",
              "29                                                                                            multimodal data as a means to understand the learning experience   \n",
              "30                                        artificial intelligence and multimodal data in the service of human decision-making: a case study in debate tutoring   \n",
              "31                                                                sensor-based data fusion for multimodal affect detection in game-based learning environments   \n",
              "32                                                                  what multimodal data can tell us about the students regulation of their learning process?   \n",
              "33                                   examining how different modes mediate adolescents interactions during their collaborative multimodal composing processes   \n",
              "34                                         investigating the impact of a real-time, multimodal student engagement analytics technology in authentic classrooms   \n",
              "35                                                                                 towards collaboration translucence: giving meaning to multimodal group data   \n",
              "36                                                                 prime: block-wise missingness handling for multi-modalities in intelligent tutoring systems   \n",
              "37                                                                early prediction of visitor engagement in science museums with multimodal learning analytics   \n",
              "38                                                                                                       multimodal learning analytics for game-based learning   \n",
              "39                                                                   multimodal learning analytics to investigate cognitive load during online problem solving   \n",
              "40                                                                                                            real-time multimodal feedback with the cpr tutor   \n",
              "41                                                  focused or stuck together: multimodal patterns reveal triads' performance in collaborative problem solving   \n",
              "42                                                                             temporal analysis of multimodal data to predict collaborative learning outcomes   \n",
              "43                                                           multimodal learning analytics to inform learning design: lessons learned from computing education   \n",
              "44                                                                       predicting learners effortful behaviour in adaptive assessment using multimodal data   \n",
              "45                                                        round or rectangular tables for collaborative problem solving? a multimodal learning analytics study   \n",
              "46                             an evaluation of an adaptive learning system based on multimodal affect recognition for learners with intellectual disabilities   \n",
              "47                                                                    from data to insights: a layered storytelling approach for multimodal learning analytics   \n",
              "48                                                                      motion-based educational games: using multi-modal data to predict players performance   \n",
              "49                                    impact of inquiry interventions on students in e-learning and classroom environments using affective computing framework   \n",
              "50                                          multi-source and multimodal data fusion for predicting academic performance in blended learning university courses   \n",
              "51                                                 controlled evaluation of a multimodal system to improve oral presentation skills in a real learning setting   \n",
              "52                                                                          utilizing multimodal data through fsqca to explain engagement in adaptive learning   \n",
              "53                   blending learning analytics and embodied design to model students' comprehension of measurement using their actions, speech, and gestures   \n",
              "54                                                                                                keep me in the loop: real-time feedback with multimodal data   \n",
              "55                                                                          storytelling with learner data: guiding student reflection on multimodal team data   \n",
              "56                                                            table tennis tutor: forehand strokes classification based on multimodal data and neural networks   \n",
              "57                                                                      affect, support, and personal factors: multimodal causal models of one-on-one coaching   \n",
              "58                                                                        multicraft: a multimodal interface for supporting and studying learning in minecraft   \n",
              "59                                                   using multimodal learning analytics to explore collaboration in a sustainability co-located tabletop game   \n",
              "60                             children's play and problem solving in motion-based educational games: synergies between human annotations and multi-modal data   \n",
              "61                                        children's play and problem-solving in motion-based learning technologies using a multi-modal mixed methods approach   \n",
              "62  improving prediction of students' performance in intelligent tutoring systems using attribute selection and ensembles of different multimodal data sources   \n",
              "63                                                                  automatic student engagement in online learning environment based on neural turing machine   \n",
              "64                                                                                          multimodal engagement analysis from facial videos in the classroom   \n",
              "65                                             examining socially shared regulation and shared physiological arousal events with multimodal learning analytics   \n",
              "66                                                                                          understanding fun in learning to code: a multi-modal data approach   \n",
              "67                               many are the ways to learn identifying multi-modal behavioral profiles of collaborative learning in constructivist activities   \n",
              "68                                                                                           once more with feeling: emotions in multimodal learning analytics   \n",
              "69                                                visualizing collaboration in teamwork: a multimodal learning analytics platform for non-verbal communication   \n",
              "70                       intermodality in multimodal learning analytics for cognitive theory development: a case from embodied design for mathematics learning   \n",
              "71                                                              a multimodal analysis of pair work engagement episodes: implications for emi lecturer training   \n",
              "72                                                                   detecting impasse during collaborative problem solving with multimodal learning analytics   \n",
              "\n",
              "                  First Author  Year Environment Type  \\\n",
              "0            Alejandro Andrade  2017         Learning   \n",
              "1           Athanasios Psaltis  2017         Learning   \n",
              "2                Daniel Spikol  2017         Learning   \n",
              "3                Daniel Spikol  2017         Learning   \n",
              "4             Daniele Di Mitri  2017         Training   \n",
              "5                Hiroki Tanaka  2017         Training   \n",
              "6              Marcelo Worsley  2017         Learning   \n",
              "7                   Nese Alyuz  2017         Learning   \n",
              "8                  Phuong Pham  2017         Learning   \n",
              "9              Volha Petukhova  2017         Training   \n",
              "10             Volha Petukhova  2017         Training   \n",
              "11               Daniel Spikol  2018         Learning   \n",
              "12                David Azcona  2018         Learning   \n",
              "13               Emma L. Starr  2018         Learning   \n",
              "14               Hua Leong Fwa  2018         Learning   \n",
              "15                  James Birt  2018         Learning   \n",
              "16            Joseph M. Reilly  2018         Learning   \n",
              "17              Luis P. Prieto  2018         Learning   \n",
              "18             Marcelo Worsley  2018         Learning   \n",
              "19                 Phuong Pham  2018         Learning   \n",
              "20                     Ran Liu  2018         Learning   \n",
              "21                     Ran Liu  2018         Learning   \n",
              "22                   Ren Nol  2018         Learning   \n",
              "23                      Su Liu  2018         Learning   \n",
              "24                Xavier Ochoa  2018         Training   \n",
              "25            Daniele Di Mitri  2019         Training   \n",
              "26        Hector Cornide-Reyes  2019         Learning   \n",
              "27                  Kit Martin  2019         Learning   \n",
              "28       Man Ching Esther Chan  2019         Learning   \n",
              "29           Michail Giannakos  2019         Training   \n",
              "30              Mutlu Cukurova  2019         Learning   \n",
              "31            Nathan Henderson  2019         Training   \n",
              "32               Sanna Jrvel  2019         Learning   \n",
              "33                Shiyan Jiang  2019         Learning   \n",
              "34                 Sinem Aslan  2019         Learning   \n",
              "35          Vanessa Echeverria  2019         Training   \n",
              "36                     Xi Yang  2019         Learning   \n",
              "37              Andrew Emerson  2020         Learning   \n",
              "38              Andrew Emerson  2020         Learning   \n",
              "39         Charlotte Larmuseau  2020         Learning   \n",
              "40            Daniele Di Mitri  2020         Training   \n",
              "41               Hana Vrzakova  2020         Learning   \n",
              "42           Jennifer K. Olsen  2020         Learning   \n",
              "43         Katerina Mangaroska  2020         Learning   \n",
              "44              Kshitij Sharma  2020         Learning   \n",
              "45              Milica Vujovic  2020         Learning   \n",
              "46         Penelope J. Standen  2020         Learning   \n",
              "47  Roberto Martinez-Maldonado  2020         Training   \n",
              "48          Serena Lee-Cultura  2020         Learning   \n",
              "49                T. S. Ashwin  2020         Learning   \n",
              "50               Wilson Chango  2020         Learning   \n",
              "51                Xavier Ochoa  2020         Training   \n",
              "52      Zacharoula Papamitsiou  2020         Learning   \n",
              "53            Avery H. Closser  2021         Learning   \n",
              "54            Daniele Di Mitri  2021         Training   \n",
              "55      Gloria Fernndez-Nieto  2021         Training   \n",
              "56  Khaleel Asyraaf Mat Sanusi  2021         Training   \n",
              "57            Lujie Karen Chen  2021         Learning   \n",
              "58             Marcelo Worsley  2021         Learning   \n",
              "59          Mara Ximena Lpez  2021         Learning   \n",
              "60          Serena Lee-Cultura  2021         Learning   \n",
              "61          Serena Lee-Cultura  2021         Learning   \n",
              "62               Wilson Chango  2021         Learning   \n",
              "63                 Xiaoyang Ma  2021         Learning   \n",
              "64                  mer Smer  2021         Learning   \n",
              "65                 Andy Nguyen  2022         Learning   \n",
              "66             Gabriella Tisza  2022         Learning   \n",
              "67             Jauwairia Nasir  2022         Learning   \n",
              "68               Marcus Kubsch  2022         Learning   \n",
              "69                   Ren Nol  2022         Learning   \n",
              "70              Sofia Tancredi  2022         Learning   \n",
              "71               Teresa Morell  2022         Training   \n",
              "72                   Yingbo Ma  2022         Learning   \n",
              "\n",
              "                          Data Collection Mediums  \\\n",
              "0                            VIDEO,LOGS,INTER,PPA   \n",
              "1                                      VIDEO,LOGS   \n",
              "2                                VIDEO,AUDIO,LOGS   \n",
              "3                            EYE,LOGS,VIDEO,AUDIO   \n",
              "4                          SENSOR,LOGS,MOTION,PPA   \n",
              "5                                 AUDIO,VIDEO,PPA   \n",
              "6                    VIDEO,AUDIO,SENSOR,PPA,INTER   \n",
              "7                           LOGS,VIDEO,SCREEN,PPA   \n",
              "8                                    VIDEO,SURVEY   \n",
              "9                                     VIDEO,AUDIO   \n",
              "10                                    VIDEO,AUDIO   \n",
              "11                       VIDEO,AUDIO,LOGS,PPA,RPA   \n",
              "12                                       LOGS,PPA   \n",
              "13                       VIDEO,AUDIO,PPA,RPA,LOGS   \n",
              "14                                     VIDEO,LOGS   \n",
              "15                                      PPA,INTER   \n",
              "16                                VIDEO,AUDIO,PPA   \n",
              "17                         EYE,VIDEO,AUDIO,MOTION   \n",
              "18                                      VIDEO,PPA   \n",
              "19                                          VIDEO   \n",
              "20                          LOGS,AUDIO,SCREEN,PPA   \n",
              "21                    VIDEO,AUDIO,LOGS,SCREEN,PPA   \n",
              "22                                  AUDIO,PPA,RPA   \n",
              "23                                   VIDEO,SENSOR   \n",
              "24                         AUDIO,VIDEO,PPA,SURVEY   \n",
              "25                              VIDEO,MOTION,LOGS   \n",
              "26                           AUDIO,SURVEY,PPA,RPA   \n",
              "27                            VIDEO,AUDIO,PPA,RPA   \n",
              "28                                    VIDEO,AUDIO   \n",
              "29                          LOGS,EYE,SENSOR,VIDEO   \n",
              "30                                   AUDIO,SURVEY   \n",
              "31                               VIDEO,SENSOR,RPA   \n",
              "32                             SENSOR,VIDEO,AUDIO   \n",
              "33                         SCREEN,INTER,PPA,AUDIO   \n",
              "34   VIDEO,LOGS,SCREEN,AUDIO,SURVEY,RPA,PPA,INTER   \n",
              "35           VIDEO,AUDIO,LOGS,SENSOR,MOTION,INTER   \n",
              "36                                  PPA,VIDEO,EYE   \n",
              "37                                 VIDEO,EYE,LOGS   \n",
              "38                                 VIDEO,LOGS,EYE   \n",
              "39                                     PPA,SENSOR   \n",
              "40                       LOGS,VIDEO,SENSOR,MOTION   \n",
              "41                  AUDIO,VIDEO,SCREEN,SURVEY,PPA   \n",
              "42                                 LOGS,AUDIO,EYE   \n",
              "43                          VIDEO,EYE,SENSOR,LOGS   \n",
              "44                               VIDEO,EYE,SENSOR   \n",
              "45                                   VIDEO,MOTION   \n",
              "46                           VIDEO,AUDIO,LOGS,RPA   \n",
              "47                   LOGS,MOTION,SENSOR,RPA,VIDEO   \n",
              "48                               VIDEO,EYE,SENSOR   \n",
              "49                                      VIDEO,PPA   \n",
              "50                                 VIDEO,LOGS,PPA   \n",
              "51                                VIDEO,AUDIO,PPA   \n",
              "52                   SURVEY,LOGS,EYE,SENSOR,VIDEO   \n",
              "53                                    VIDEO,AUDIO   \n",
              "54                SURVEY,LOGS,VIDEO,SENSOR,MOTION   \n",
              "55                                SENSOR,LOGS,RPA   \n",
              "56                             VIDEO,MOTION,INTER   \n",
              "57                             AUDIO,VIDEO,SURVEY   \n",
              "58  AUDIO,EYE,TEXT,VIDEO,SCREEN,INTER,SURVEY,LOGS   \n",
              "59                        SURVEY,LOGS,AUDIO,VIDEO   \n",
              "60                          VIDEO,SENSOR,EYE,LOGS   \n",
              "61                          VIDEO,SENSOR,EYE,LOGS   \n",
              "62                             LOGS,VIDEO,EYE,PPA   \n",
              "63                                          VIDEO   \n",
              "64                                          VIDEO   \n",
              "65                             VIDEO,AUDIO,SENSOR   \n",
              "66                               SENSOR,VIDEO,PPA   \n",
              "67                    VIDEO,AUDIO,LOGS,PPA,SURVEY   \n",
              "68                               SURVEY,PPA,AUDIO   \n",
              "69                          AUDIO,VIDEO,RPA,INTER   \n",
              "70                          EYE,VIDEO,AUDIO,INTER   \n",
              "71                                VIDEO,AUDIO,PPA   \n",
              "72                                    VIDEO,AUDIO   \n",
              "\n",
              "                                           Modalities  \\\n",
              "0                            GAZE,LOGS,INTER,PPA,GEST   \n",
              "1                                    POSE,AFFECT,LOGS   \n",
              "2                                           POSE,PROS   \n",
              "3                                 GAZE,LOGS,PROS,POSE   \n",
              "4                                    PULSE,ACT,AFFECT   \n",
              "5                                    POSE,PROS,AFFECT   \n",
              "6                    GEST,PPA,EDA,ACT,PROS,QUAL,INTER   \n",
              "7                                AFFECT,POSE,LOGS,PPA   \n",
              "8                                 PULSE,AFFECT,SURVEY   \n",
              "9                                           PROS,GEST   \n",
              "10                        GEST,TRANS,PROS,SURVEY,GAZE   \n",
              "11                        POSE,GEST,PROS,LOGS,PPA,RPA   \n",
              "12                                           LOGS,PPA   \n",
              "13                             POSE,PROS,PPA,RPA,LOGS   \n",
              "14                                      POSE,ACT,LOGS   \n",
              "15                                          PPA,TRANS   \n",
              "16                                  PPA,RPA,POSE,GEST   \n",
              "17                                GAZE,PROS,ACT,PIXEL   \n",
              "18                                      GEST,QUAL,PPA   \n",
              "19                                       AFFECT,PULSE   \n",
              "20                            LOGS,TRANS,ACT,QUAL,PPA   \n",
              "21                                     TRANS,QUAL,PPA   \n",
              "22                                           RPA,PROS   \n",
              "23                                  PULSE,AFFECT,GAZE   \n",
              "24                                 PPA,GAZE,POSE,PROS   \n",
              "25                                          POSE,LOGS   \n",
              "26                               SURVEY,TRANS,PPA,RPA   \n",
              "27                                  TRANS,AFFECT,QUAL   \n",
              "28                                     POSE,GAZE,PROS   \n",
              "29               EEG,GAZE,LOGS,PULSE,EDA,TEMP,BP,POSE   \n",
              "30                                        AFFECT,LOGS   \n",
              "31                                    POSE,EDA,AFFECT   \n",
              "32                                    EDA,AFFECT,QUAL   \n",
              "33                                   INTER,QUAL,TRANS   \n",
              "34             AFFECT,LOGS,POSE,QUAL,INTER,SURVEY,RPA   \n",
              "35                 POSE,LOGS,TRANS,EDA,ACT,PROS,INTER   \n",
              "36                                   LOGS,AFFECT,GAZE   \n",
              "37                         POSE,GEST,AFFECT,GAZE,LOGS   \n",
              "38                               AFFECT,GAZE,LOGS,PPA   \n",
              "39                                      PPA,PULSE,EDA   \n",
              "40                                      POSE,EMG,GEST   \n",
              "41                                  PROS,ACT,GEST,PPA   \n",
              "42                          GAZE,LOGS,PROS,TRANS,QUAL   \n",
              "43                    LOGS,GAZE,EDA,PULSE,AFFECT,TEMP   \n",
              "44                     EDA,TEMP,PULSE,EEG,GAZE,AFFECT   \n",
              "45                                      POSE,GEST,ACT   \n",
              "46                AFFECT,POSE,LOGS,RPA,GAZE,PROS,GEST   \n",
              "47                                  POSE,EDA,LOGS,RPA   \n",
              "48                           PULSE,TEMP,EDA,GAZE,POSE   \n",
              "49                                   AFFECT,POSE,GEST   \n",
              "50                                  LOGS,POSE,RPA,ACT   \n",
              "51                                      POSE,PROS,PPA   \n",
              "52      PULSE,AFFECT,EEG,GAZE,LOGS,BP,TEMP,EDA,SURVEY   \n",
              "53                                                RPA   \n",
              "54                               POSE,EMG,GEST,SURVEY   \n",
              "55                                EDA,LOGS,RPA,AFFECT   \n",
              "56                                POSE,GEST,ACT,INTER   \n",
              "57                      PROS,GAZE,TRANS,AFFECT,SURVEY   \n",
              "58             PROS,TRANS,GAZE,TEXT,INTER,SURVEY,LOGS   \n",
              "59                              LOGS,SURVEY,GAZE,PROS   \n",
              "60     ACT,GAZE,EDA,PULSE,AFFECT,FATIG,LOGS,QUAL,TEMP   \n",
              "61  ACT,GAZE,EDA,PULSE,AFFECT,FATIG,LOGS,QUAL,TEMP,BP   \n",
              "62                               AFFECT,LOGS,GAZE,PPA   \n",
              "63                                          POSE,GAZE   \n",
              "64                                        POSE,AFFECT   \n",
              "65                                           QUAL,EDA   \n",
              "66                           TEMP,PULSE,EDA,BP,AFFECT   \n",
              "67                        PROS,AFFECT,GAZE,TRANS,LOGS   \n",
              "68                     INTER,SURVEY,TRANS,PROS,AFFECT   \n",
              "69                           PROS,POSE,RPA,INTER,QUAL   \n",
              "70                         GAZE,GEST,TRANS,POSE,INTER   \n",
              "71                            TRANS,PPA,QUAL,POSE,ACT   \n",
              "72                         TRANS,PROS,SPECT,GAZE,POSE   \n",
              "\n",
              "           Analysis Methods Fusion Types    Publication Environment Setting  \\\n",
              "0                CLUST,QUAL       HYBRID            LAK                BLND   \n",
              "1                       CLS         LATE        T-CIAIG                BLND   \n",
              "2                       REG          MID           CSCL                PHYS   \n",
              "3                       CLS          MID          ICALT                VIRT   \n",
              "4                       REG          MID            LAK                BLND   \n",
              "5                 REG,STATS          MID           PLOS                VIRT   \n",
              "6     STATS,CLUST,QUAL,PATT        EARLY         IJAIED                PHYS   \n",
              "7                       CLS       HYBRID            MIE                VIRT   \n",
              "8                       CLS          MID           AIED                VIRT   \n",
              "9            CLS,QUAL,STATS          MID    INTERSPEECH                PHYS   \n",
              "10           STATS,CLS,QUAL          MID           ICMI                PHYS   \n",
              "11                  REG,CLS          MID           JCAL                BLND   \n",
              "12                CLS,STATS          MID            FIE                VIRT   \n",
              "13               STATS,QUAL          OTH           ICLS                BLND   \n",
              "14                      CLS          MID           PPIG                VIRT   \n",
              "15               QUAL,STATS          OTH    Information                BLND   \n",
              "16         CLUST,PATT,STATS          OTH            EDM                BLND   \n",
              "17  NET,CLS,STATS,PATT,QUAL       HYBRID           JCAL                PHYS   \n",
              "18           CLUST,CLS,QUAL       HYBRID            LAK                PHYS   \n",
              "19                      REG         LATE            ITS                VIRT   \n",
              "20           STATS,REG,QUAL          MID            JLA                VIRT   \n",
              "21                CLS,STATS          MID           JCAL                VIRT   \n",
              "22           QUAL,NET,STATS          OTH         Access                PHYS   \n",
              "23                      CLS          MID           TALE                UNSP   \n",
              "24           CLS,STATS,QUAL         LATE            LAK                BLND   \n",
              "25                      CLS          MID           CAIM                BLND   \n",
              "26                NET,STATS      MID,OTH        Sensors                PHYS   \n",
              "27                     QUAL          OTH           ICQE                VIRT   \n",
              "28                CLS,CLUST         LATE         MLPALA                PHYS   \n",
              "29                REG,STATS       HYBRID           IJIM                VIRT   \n",
              "30                      CLS          MID           BJET                UNSP   \n",
              "31                      CLS       HYBRID            EDM                VIRT   \n",
              "32                     QUAL          OTH            LAI                BLND   \n",
              "33                     QUAL          OTH            ILE                VIRT   \n",
              "34           QUAL,STATS,CLS         LATE            CHI                VIRT   \n",
              "35                     QUAL          OTH            CHI                PHYS   \n",
              "36                CLS,STATS       HYBRID            MMM                VIRT   \n",
              "37                      REG          MID           ICMI                VIRT   \n",
              "38                CLS,STATS          MID           BJET                VIRT   \n",
              "39                STATS,CLS        EARLY           BJET                VIRT   \n",
              "40                      CLS       HYBRID           AIED                PHYS   \n",
              "41               STATS,PATT          MID            LAK                VIRT   \n",
              "42                      REG          MID           BJET                VIRT   \n",
              "43                      CLS       HYBRID            JLA                VIRT   \n",
              "44           CLUST,CLS,PATT          MID            LAK                VIRT   \n",
              "45               STATS,QUAL          OTH           BJET                BLND   \n",
              "46                CLS,STATS       HYBRID           BJET                VIRT   \n",
              "47                     QUAL          OTH            CHI                BLND   \n",
              "48                      CLS          MID            COG                BLND   \n",
              "49           CLS,STATS,PATT          MID          UMUAI          PHYS, VIRT   \n",
              "50           CLS,QUAL,STATS     MID,LATE            CEE                BLND   \n",
              "51                    STATS          OTH           BJET                BLND   \n",
              "52                     PATT       HYBRID            TLT                VIRT   \n",
              "53                CLUST,REG          MID          IJCCI                PHYS   \n",
              "54           CLS,QUAL,STATS       HYBRID         IJAIED                PHYS   \n",
              "55                     QUAL          OTH            TLT                BLND   \n",
              "56                 CLS,QUAL       HYBRID        Sensors                PHYS   \n",
              "57                STATS,NET       HYBRID           JEDM                PHYS   \n",
              "58                     QUAL          OTH           HCII                VIRT   \n",
              "59                    STATS          OTH          ECGBL                BLND   \n",
              "60               STATS,QUAL          OTH            IDC                BLND   \n",
              "61           STATS,QUAL,CLS       HYBRID          IJCCI                BLND   \n",
              "62                      CLS  HYBRID,LATE           JCHE                VIRT   \n",
              "63                      CLS          MID          IJIET                VIRT   \n",
              "64                      CLS   EARLY,LATE            TAC                PHYS   \n",
              "65           PATT,CLS,CLUST       HYBRID           BJET                PHYS   \n",
              "66                REG,STATS          MID            IDC                VIRT   \n",
              "67     STATS,QUAL,CLUST,CLS       HYBRID         IJCSCL                BLND   \n",
              "68            CLS,REG,STATS          OTH  MMLA Handbook                PHYS   \n",
              "69                     QUAL          OTH          DAMLE                PHYS   \n",
              "70          PATT,QUAL,STATS          OTH  MMLA Handbook                VIRT   \n",
              "71                     QUAL          OTH           JEAP                PHYS   \n",
              "72                      CLS       HYBRID            LAK                VIRT   \n",
              "\n",
              "   Environment Subject Participant Structure Didactic Nature  \\\n",
              "0                 STEM                   IND           INSTR   \n",
              "1                  HUM                   IND             INF   \n",
              "2                 STEM                 MULTI           INSTR   \n",
              "3                 STEM                 MULTI           INSTR   \n",
              "4                 UNSP                   IND            UNSP   \n",
              "5                  HUM                   IND           TRAIN   \n",
              "6                 STEM                 MULTI             INF   \n",
              "7                 STEM                   IND           INSTR   \n",
              "8                 STEM                   IND           INSTR   \n",
              "9                  HUM                 MULTI           TRAIN   \n",
              "10                 HUM                 MULTI           TRAIN   \n",
              "11                STEM                 MULTI           INSTR   \n",
              "12                STEM                   IND           INSTR   \n",
              "13                STEM                 MULTI             INF   \n",
              "14                STEM                   IND           INSTR   \n",
              "15                STEM                   IND           INSTR   \n",
              "16                STEM                 MULTI           INSTR   \n",
              "17                STEM                 MULTI           INSTR   \n",
              "18                STEM                 MULTI           INSTR   \n",
              "19                STEM                   IND           INSTR   \n",
              "20                STEM                   IND           INSTR   \n",
              "21                STEM            IND, MULTI           INSTR   \n",
              "22                STEM                 MULTI             INF   \n",
              "23                UNSP                   IND           INSTR   \n",
              "24                 HUM                   IND           TRAIN   \n",
              "25                 PSY                   IND           TRAIN   \n",
              "26                STEM                 MULTI           INSTR   \n",
              "27                STEM                 MULTI             INF   \n",
              "28                STEM            IND, MULTI           INSTR   \n",
              "29                 PSY                   IND             INF   \n",
              "30                 HUM                   IND           TRAIN   \n",
              "31                STEM                   IND           TRAIN   \n",
              "32                STEM                 MULTI           INSTR   \n",
              "33                STEM                 MULTI           INSTR   \n",
              "34                STEM                   IND           INSTR   \n",
              "35                STEM                 MULTI           TRAIN   \n",
              "36                STEM                   IND           INSTR   \n",
              "37                STEM                   IND             INF   \n",
              "38                STEM                   IND             INF   \n",
              "39                STEM                   IND           INSTR   \n",
              "40                 PSY                   IND           TRAIN   \n",
              "41                STEM                 MULTI           INSTR   \n",
              "42                STEM                 MULTI           INSTR   \n",
              "43                STEM                   IND           INSTR   \n",
              "44                STEM                   IND           INSTR   \n",
              "45           HUM, STEM                 MULTI           INSTR   \n",
              "46      HUM, OTH, STEM                   IND           INSTR   \n",
              "47                STEM                 MULTI           TRAIN   \n",
              "48                STEM                   IND           INSTR   \n",
              "49                UNSP            IND, MULTI           INSTR   \n",
              "50                STEM                   IND           INSTR   \n",
              "51                 HUM                   IND           TRAIN   \n",
              "52                STEM                   IND             INF   \n",
              "53                STEM                   IND             INF   \n",
              "54                 PSY                   IND           TRAIN   \n",
              "55                STEM                 MULTI           TRAIN   \n",
              "56                 PSY                   IND           TRAIN   \n",
              "57                STEM                   IND           INSTR   \n",
              "58                STEM                   IND             INF   \n",
              "59                STEM                 MULTI           INSTR   \n",
              "60                STEM                   IND           INSTR   \n",
              "61                STEM                   IND           INSTR   \n",
              "62                STEM                   IND           INSTR   \n",
              "63                UNSP                   IND           INSTR   \n",
              "64           HUM, STEM                 MULTI           INSTR   \n",
              "65                STEM                 MULTI           INSTR   \n",
              "66                STEM                   IND           INSTR   \n",
              "67                STEM                 MULTI           INSTR   \n",
              "68                STEM                   IND           INSTR   \n",
              "69                 HUM                 MULTI             INF   \n",
              "70                STEM                   IND           INSTR   \n",
              "71                 OTH                 MULTI           TRAIN   \n",
              "72                STEM                 MULTI           INSTR   \n",
              "\n",
              "   Level of Instruction or Training Analysis Approach  \n",
              "0                               K12                MB  \n",
              "1                               K12                MB  \n",
              "2                               UNI                MB  \n",
              "3                               UNI                MB  \n",
              "4                               UNI                MB  \n",
              "5                          K12, UNI                MF  \n",
              "6                          K12, UNI                MB  \n",
              "7                               K12                MB  \n",
              "8                              UNSP                MB  \n",
              "9                               K12                MB  \n",
              "10                              K12                MB  \n",
              "11                              UNI                MB  \n",
              "12                              UNI                MB  \n",
              "13                              UNI                MF  \n",
              "14                              UNI                MB  \n",
              "15                              UNI                MF  \n",
              "16                              UNI            MB, MF  \n",
              "17                             PROF                MB  \n",
              "18                              UNI                MB  \n",
              "19                              UNI                MB  \n",
              "20                              K12                MB  \n",
              "21                              K12            MB, MF  \n",
              "22                              UNI            MB, MF  \n",
              "23                             UNSP                MB  \n",
              "24                              UNI                MB  \n",
              "25                              UNI                MB  \n",
              "26                              UNI            MB, MF  \n",
              "27                             UNSP            MB, MF  \n",
              "28                             UNSP                MB  \n",
              "29                              UNI                MB  \n",
              "30                             UNSP            MB, MF  \n",
              "31                              UNI                MB  \n",
              "32                              K12                MF  \n",
              "33                              K12                MB  \n",
              "34                              K12                MB  \n",
              "35                              UNI                MB  \n",
              "36                              UNI                MB  \n",
              "37                              K12                MB  \n",
              "38                              UNI                MB  \n",
              "39                         K12, UNI            MB, MF  \n",
              "40                             PROF                MB  \n",
              "41                              UNI                MF  \n",
              "42                              K12                MB  \n",
              "43                              UNI                MB  \n",
              "44                              UNI                MB  \n",
              "45                              K12                MF  \n",
              "46                              K12                MB  \n",
              "47                              UNI                MF  \n",
              "48                              K12                MB  \n",
              "49                              UNI                MB  \n",
              "50                              UNI                MB  \n",
              "51                             UNSP                MF  \n",
              "52                              UNI                MF  \n",
              "53                         K12, UNI            MB, MF  \n",
              "54                             PROF                MB  \n",
              "55                              UNI                MF  \n",
              "56                              UNI                MB  \n",
              "57                              K12                MB  \n",
              "58                              K12                MF  \n",
              "59                              UNI                MF  \n",
              "60                              K12                MF  \n",
              "61                              K12            MB, MF  \n",
              "62                              UNI                MB  \n",
              "63                             UNSP                MB  \n",
              "64                              K12                MB  \n",
              "65                              K12                MB  \n",
              "66                              K12            MB, MF  \n",
              "67                              K12                MB  \n",
              "68                              K12            MB, MF  \n",
              "69                        PROF, UNI                MF  \n",
              "70                              K12                MF  \n",
              "71                             PROF                MF  \n",
              "72                              K12                MB  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2a2e13c-2446-4c0f-b656-ea0a3f777016\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UUID</th>\n",
              "      <th>Title</th>\n",
              "      <th>First Author</th>\n",
              "      <th>Year</th>\n",
              "      <th>Environment Type</th>\n",
              "      <th>Data Collection Mediums</th>\n",
              "      <th>Modalities</th>\n",
              "      <th>Analysis Methods</th>\n",
              "      <th>Fusion Types</th>\n",
              "      <th>Publication</th>\n",
              "      <th>Environment Setting</th>\n",
              "      <th>Environment Subject</th>\n",
              "      <th>Participant Structure</th>\n",
              "      <th>Didactic Nature</th>\n",
              "      <th>Level of Instruction or Training</th>\n",
              "      <th>Analysis Approach</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>818492192</td>\n",
              "      <td>understanding student learning trajectories using multimodal learning analytics within an embodied-interaction learning environment</td>\n",
              "      <td>Alejandro Andrade</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,LOGS,INTER,PPA</td>\n",
              "      <td>GAZE,LOGS,INTER,PPA,GEST</td>\n",
              "      <td>CLUST,QUAL</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>LAK</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3408664396</td>\n",
              "      <td>multimodal student engagement recognition in prosocial games</td>\n",
              "      <td>Athanasios Psaltis</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,LOGS</td>\n",
              "      <td>POSE,AFFECT,LOGS</td>\n",
              "      <td>CLS</td>\n",
              "      <td>LATE</td>\n",
              "      <td>T-CIAIG</td>\n",
              "      <td>BLND</td>\n",
              "      <td>HUM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INF</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1118315889</td>\n",
              "      <td>using multimodal learning analytics to identify aspects of collaboration in project-based learning</td>\n",
              "      <td>Daniel Spikol</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO,LOGS</td>\n",
              "      <td>POSE,PROS</td>\n",
              "      <td>REG</td>\n",
              "      <td>MID</td>\n",
              "      <td>CSCL</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3339002981</td>\n",
              "      <td>estimation of success in collaborative learning based on multimodal learning analytics features</td>\n",
              "      <td>Daniel Spikol</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning</td>\n",
              "      <td>EYE,LOGS,VIDEO,AUDIO</td>\n",
              "      <td>GAZE,LOGS,PROS,POSE</td>\n",
              "      <td>CLS</td>\n",
              "      <td>MID</td>\n",
              "      <td>ICALT</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1609706685</td>\n",
              "      <td>learning pulse: a machine learning approach for predicting performance in self-regulated learning using multimodal data</td>\n",
              "      <td>Daniele Di Mitri</td>\n",
              "      <td>2017</td>\n",
              "      <td>Training</td>\n",
              "      <td>SENSOR,LOGS,MOTION,PPA</td>\n",
              "      <td>PULSE,ACT,AFFECT</td>\n",
              "      <td>REG</td>\n",
              "      <td>MID</td>\n",
              "      <td>LAK</td>\n",
              "      <td>BLND</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>IND</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3093310941</td>\n",
              "      <td>embodied conversational agents for multimodal automated social skills training in people with autism spectrum disorders</td>\n",
              "      <td>Hiroki Tanaka</td>\n",
              "      <td>2017</td>\n",
              "      <td>Training</td>\n",
              "      <td>AUDIO,VIDEO,PPA</td>\n",
              "      <td>POSE,PROS,AFFECT</td>\n",
              "      <td>REG,STATS</td>\n",
              "      <td>MID</td>\n",
              "      <td>PLOS</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>HUM</td>\n",
              "      <td>IND</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>K12, UNI</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3095923626</td>\n",
              "      <td>a multimodal analysis of making</td>\n",
              "      <td>Marcelo Worsley</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO,SENSOR,PPA,INTER</td>\n",
              "      <td>GEST,PPA,EDA,ACT,PROS,QUAL,INTER</td>\n",
              "      <td>STATS,CLUST,QUAL,PATT</td>\n",
              "      <td>EARLY</td>\n",
              "      <td>IJAIED</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INF</td>\n",
              "      <td>K12, UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2456887548</td>\n",
              "      <td>an unobtrusive and multimodal approach for behavioral engagement detection of students</td>\n",
              "      <td>Nese Alyuz</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning</td>\n",
              "      <td>LOGS,VIDEO,SCREEN,PPA</td>\n",
              "      <td>AFFECT,POSE,LOGS,PPA</td>\n",
              "      <td>CLS</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>MIE</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1374035721</td>\n",
              "      <td>attentivelearner2: a multimodal approach for improving mooc learning on mobile devices</td>\n",
              "      <td>Phuong Pham</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,SURVEY</td>\n",
              "      <td>PULSE,AFFECT,SURVEY</td>\n",
              "      <td>CLS</td>\n",
              "      <td>MID</td>\n",
              "      <td>AIED</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>85990093</td>\n",
              "      <td>multimodal markers of persuasive speech : designing a virtual debate coach</td>\n",
              "      <td>Volha Petukhova</td>\n",
              "      <td>2017</td>\n",
              "      <td>Training</td>\n",
              "      <td>VIDEO,AUDIO</td>\n",
              "      <td>PROS,GEST</td>\n",
              "      <td>CLS,QUAL,STATS</td>\n",
              "      <td>MID</td>\n",
              "      <td>INTERSPEECH</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>HUM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>957160695</td>\n",
              "      <td>virtual debate coach design: assessing multimodal argumentation performance</td>\n",
              "      <td>Volha Petukhova</td>\n",
              "      <td>2017</td>\n",
              "      <td>Training</td>\n",
              "      <td>VIDEO,AUDIO</td>\n",
              "      <td>GEST,TRANS,PROS,SURVEY,GAZE</td>\n",
              "      <td>STATS,CLS,QUAL</td>\n",
              "      <td>MID</td>\n",
              "      <td>ICMI</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>HUM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1637690235</td>\n",
              "      <td>supervised machine learning in multimodal learning analytics for estimating success in project-based learning</td>\n",
              "      <td>Daniel Spikol</td>\n",
              "      <td>2018</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO,LOGS,PPA,RPA</td>\n",
              "      <td>POSE,GEST,PROS,LOGS,PPA,RPA</td>\n",
              "      <td>REG,CLS</td>\n",
              "      <td>MID</td>\n",
              "      <td>JCAL</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1886134458</td>\n",
              "      <td>personalizing computer science education by leveraging multimodal learning analytics</td>\n",
              "      <td>David Azcona</td>\n",
              "      <td>2018</td>\n",
              "      <td>Learning</td>\n",
              "      <td>LOGS,PPA</td>\n",
              "      <td>LOGS,PPA</td>\n",
              "      <td>CLS,STATS</td>\n",
              "      <td>MID</td>\n",
              "      <td>FIE</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2181637610</td>\n",
              "      <td>toward using multi-modal learning analytics to support and measure collaboration in co-located dyads</td>\n",
              "      <td>Emma L. Starr</td>\n",
              "      <td>2018</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO,PPA,RPA,LOGS</td>\n",
              "      <td>POSE,PROS,PPA,RPA,LOGS</td>\n",
              "      <td>STATS,QUAL</td>\n",
              "      <td>OTH</td>\n",
              "      <td>ICLS</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INF</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>483140962</td>\n",
              "      <td>investigating multimodal affect sensing in an affective tutoring system using unobtrusive sensors</td>\n",
              "      <td>Hua Leong Fwa</td>\n",
              "      <td>2018</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,LOGS</td>\n",
              "      <td>POSE,ACT,LOGS</td>\n",
              "      <td>CLS</td>\n",
              "      <td>MID</td>\n",
              "      <td>PPIG</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3146393211</td>\n",
              "      <td>mobile mixed reality for experiential learning and simulation in medical and health sciences education</td>\n",
              "      <td>James Birt</td>\n",
              "      <td>2018</td>\n",
              "      <td>Learning</td>\n",
              "      <td>PPA,INTER</td>\n",
              "      <td>PPA,TRANS</td>\n",
              "      <td>QUAL,STATS</td>\n",
              "      <td>OTH</td>\n",
              "      <td>Information</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3308658121</td>\n",
              "      <td>exploring collaboration using motion sensors and multi-modal learning analytics</td>\n",
              "      <td>Joseph M. Reilly</td>\n",
              "      <td>2018</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO,PPA</td>\n",
              "      <td>PPA,RPA,POSE,GEST</td>\n",
              "      <td>CLUST,PATT,STATS</td>\n",
              "      <td>OTH</td>\n",
              "      <td>EDM</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB, MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3135645357</td>\n",
              "      <td>multimodal teaching analytics: automated extraction of orchestration graphs from wearable sensor data</td>\n",
              "      <td>Luis P. Prieto</td>\n",
              "      <td>2018</td>\n",
              "      <td>Learning</td>\n",
              "      <td>EYE,VIDEO,AUDIO,MOTION</td>\n",
              "      <td>GAZE,PROS,ACT,PIXEL</td>\n",
              "      <td>NET,CLS,STATS,PATT,QUAL</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>JCAL</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>PROF</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3309250332</td>\n",
              "      <td>(dis)engagement matters: identifying efficacious learning practices with multimodal learning analytics</td>\n",
              "      <td>Marcelo Worsley</td>\n",
              "      <td>2018</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,PPA</td>\n",
              "      <td>GEST,QUAL,PPA</td>\n",
              "      <td>CLUST,CLS,QUAL</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>LAK</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2836996318</td>\n",
              "      <td>predicting learners' emotions in mobile mooc learning via a multimodal intelligent tutor</td>\n",
              "      <td>Phuong Pham</td>\n",
              "      <td>2018</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO</td>\n",
              "      <td>AFFECT,PULSE</td>\n",
              "      <td>REG</td>\n",
              "      <td>LATE</td>\n",
              "      <td>ITS</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3783339081</td>\n",
              "      <td>a novel method for the in-depth multimodal analysis of student learning trajectories in intelligent tutoring systems</td>\n",
              "      <td>Ran Liu</td>\n",
              "      <td>2018</td>\n",
              "      <td>Learning</td>\n",
              "      <td>LOGS,AUDIO,SCREEN,PPA</td>\n",
              "      <td>LOGS,TRANS,ACT,QUAL,PPA</td>\n",
              "      <td>STATS,REG,QUAL</td>\n",
              "      <td>MID</td>\n",
              "      <td>JLA</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3796180663</td>\n",
              "      <td>learning linkages: integrating data streams of multiple modalities and timescales</td>\n",
              "      <td>Ran Liu</td>\n",
              "      <td>2018</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO,LOGS,SCREEN,PPA</td>\n",
              "      <td>TRANS,QUAL,PPA</td>\n",
              "      <td>CLS,STATS</td>\n",
              "      <td>MID</td>\n",
              "      <td>JCAL</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND, MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB, MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2345021698</td>\n",
              "      <td>exploring collaborative writing of user stories with multimodal learning analytics: a case study on a software engineering course</td>\n",
              "      <td>Ren Nol</td>\n",
              "      <td>2018</td>\n",
              "      <td>Learning</td>\n",
              "      <td>AUDIO,PPA,RPA</td>\n",
              "      <td>RPA,PROS</td>\n",
              "      <td>QUAL,NET,STATS</td>\n",
              "      <td>OTH</td>\n",
              "      <td>Access</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INF</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB, MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>804659204</td>\n",
              "      <td>towards smart educational recommendations with reinforcement learning in classroom</td>\n",
              "      <td>Su Liu</td>\n",
              "      <td>2018</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,SENSOR</td>\n",
              "      <td>PULSE,AFFECT,GAZE</td>\n",
              "      <td>CLS</td>\n",
              "      <td>MID</td>\n",
              "      <td>TALE</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2497456347</td>\n",
              "      <td>the rap system: automatic feedback of oral presentation skills using multimodal analysis and low-cost sensors</td>\n",
              "      <td>Xavier Ochoa</td>\n",
              "      <td>2018</td>\n",
              "      <td>Training</td>\n",
              "      <td>AUDIO,VIDEO,PPA,SURVEY</td>\n",
              "      <td>PPA,GAZE,POSE,PROS</td>\n",
              "      <td>CLS,STATS,QUAL</td>\n",
              "      <td>LATE</td>\n",
              "      <td>LAK</td>\n",
              "      <td>BLND</td>\n",
              "      <td>HUM</td>\n",
              "      <td>IND</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2070224207</td>\n",
              "      <td>detecting medical simulation errors with machine learning and multimodal data</td>\n",
              "      <td>Daniele Di Mitri</td>\n",
              "      <td>2019</td>\n",
              "      <td>Training</td>\n",
              "      <td>VIDEO,MOTION,LOGS</td>\n",
              "      <td>POSE,LOGS</td>\n",
              "      <td>CLS</td>\n",
              "      <td>MID</td>\n",
              "      <td>CAIM</td>\n",
              "      <td>BLND</td>\n",
              "      <td>PSY</td>\n",
              "      <td>IND</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>4019205162</td>\n",
              "      <td>introducing low-cost sensors into the classroom settings: improving the assessment in agile practices with multimodal learning analytics</td>\n",
              "      <td>Hector Cornide-Reyes</td>\n",
              "      <td>2019</td>\n",
              "      <td>Learning</td>\n",
              "      <td>AUDIO,SURVEY,PPA,RPA</td>\n",
              "      <td>SURVEY,TRANS,PPA,RPA</td>\n",
              "      <td>NET,STATS</td>\n",
              "      <td>MID,OTH</td>\n",
              "      <td>Sensors</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB, MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1847468084</td>\n",
              "      <td>computationally augmented ethnography: emotion tracking and learning in museum games</td>\n",
              "      <td>Kit Martin</td>\n",
              "      <td>2019</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO,PPA,RPA</td>\n",
              "      <td>TRANS,AFFECT,QUAL</td>\n",
              "      <td>QUAL</td>\n",
              "      <td>OTH</td>\n",
              "      <td>ICQE</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INF</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>MB, MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1326191931</td>\n",
              "      <td>multimodal learning analytics in a laboratory classroom</td>\n",
              "      <td>Man Ching Esther Chan</td>\n",
              "      <td>2019</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO</td>\n",
              "      <td>POSE,GAZE,PROS</td>\n",
              "      <td>CLS,CLUST</td>\n",
              "      <td>LATE</td>\n",
              "      <td>MLPALA</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND, MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>4278392816</td>\n",
              "      <td>multimodal data as a means to understand the learning experience</td>\n",
              "      <td>Michail Giannakos</td>\n",
              "      <td>2019</td>\n",
              "      <td>Training</td>\n",
              "      <td>LOGS,EYE,SENSOR,VIDEO</td>\n",
              "      <td>EEG,GAZE,LOGS,PULSE,EDA,TEMP,BP,POSE</td>\n",
              "      <td>REG,STATS</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>IJIM</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>PSY</td>\n",
              "      <td>IND</td>\n",
              "      <td>INF</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1576545447</td>\n",
              "      <td>artificial intelligence and multimodal data in the service of human decision-making: a case study in debate tutoring</td>\n",
              "      <td>Mutlu Cukurova</td>\n",
              "      <td>2019</td>\n",
              "      <td>Learning</td>\n",
              "      <td>AUDIO,SURVEY</td>\n",
              "      <td>AFFECT,LOGS</td>\n",
              "      <td>CLS</td>\n",
              "      <td>MID</td>\n",
              "      <td>BJET</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>HUM</td>\n",
              "      <td>IND</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>MB, MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>853680639</td>\n",
              "      <td>sensor-based data fusion for multimodal affect detection in game-based learning environments</td>\n",
              "      <td>Nathan Henderson</td>\n",
              "      <td>2019</td>\n",
              "      <td>Training</td>\n",
              "      <td>VIDEO,SENSOR,RPA</td>\n",
              "      <td>POSE,EDA,AFFECT</td>\n",
              "      <td>CLS</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>EDM</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>3398902089</td>\n",
              "      <td>what multimodal data can tell us about the students regulation of their learning process?</td>\n",
              "      <td>Sanna Jrvel</td>\n",
              "      <td>2019</td>\n",
              "      <td>Learning</td>\n",
              "      <td>SENSOR,VIDEO,AUDIO</td>\n",
              "      <td>EDA,AFFECT,QUAL</td>\n",
              "      <td>QUAL</td>\n",
              "      <td>OTH</td>\n",
              "      <td>LAI</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>86191824</td>\n",
              "      <td>examining how different modes mediate adolescents interactions during their collaborative multimodal composing processes</td>\n",
              "      <td>Shiyan Jiang</td>\n",
              "      <td>2019</td>\n",
              "      <td>Learning</td>\n",
              "      <td>SCREEN,INTER,PPA,AUDIO</td>\n",
              "      <td>INTER,QUAL,TRANS</td>\n",
              "      <td>QUAL</td>\n",
              "      <td>OTH</td>\n",
              "      <td>ILE</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>3448122334</td>\n",
              "      <td>investigating the impact of a real-time, multimodal student engagement analytics technology in authentic classrooms</td>\n",
              "      <td>Sinem Aslan</td>\n",
              "      <td>2019</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,LOGS,SCREEN,AUDIO,SURVEY,RPA,PPA,INTER</td>\n",
              "      <td>AFFECT,LOGS,POSE,QUAL,INTER,SURVEY,RPA</td>\n",
              "      <td>QUAL,STATS,CLS</td>\n",
              "      <td>LATE</td>\n",
              "      <td>CHI</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1296637108</td>\n",
              "      <td>towards collaboration translucence: giving meaning to multimodal group data</td>\n",
              "      <td>Vanessa Echeverria</td>\n",
              "      <td>2019</td>\n",
              "      <td>Training</td>\n",
              "      <td>VIDEO,AUDIO,LOGS,SENSOR,MOTION,INTER</td>\n",
              "      <td>POSE,LOGS,TRANS,EDA,ACT,PROS,INTER</td>\n",
              "      <td>QUAL</td>\n",
              "      <td>OTH</td>\n",
              "      <td>CHI</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1019093033</td>\n",
              "      <td>prime: block-wise missingness handling for multi-modalities in intelligent tutoring systems</td>\n",
              "      <td>Xi Yang</td>\n",
              "      <td>2019</td>\n",
              "      <td>Learning</td>\n",
              "      <td>PPA,VIDEO,EYE</td>\n",
              "      <td>LOGS,AFFECT,GAZE</td>\n",
              "      <td>CLS,STATS</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>MMM</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1581261659</td>\n",
              "      <td>early prediction of visitor engagement in science museums with multimodal learning analytics</td>\n",
              "      <td>Andrew Emerson</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,EYE,LOGS</td>\n",
              "      <td>POSE,GEST,AFFECT,GAZE,LOGS</td>\n",
              "      <td>REG</td>\n",
              "      <td>MID</td>\n",
              "      <td>ICMI</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INF</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>1598166515</td>\n",
              "      <td>multimodal learning analytics for game-based learning</td>\n",
              "      <td>Andrew Emerson</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,LOGS,EYE</td>\n",
              "      <td>AFFECT,GAZE,LOGS,PPA</td>\n",
              "      <td>CLS,STATS</td>\n",
              "      <td>MID</td>\n",
              "      <td>BJET</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INF</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>205660768</td>\n",
              "      <td>multimodal learning analytics to investigate cognitive load during online problem solving</td>\n",
              "      <td>Charlotte Larmuseau</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>PPA,SENSOR</td>\n",
              "      <td>PPA,PULSE,EDA</td>\n",
              "      <td>STATS,CLS</td>\n",
              "      <td>EARLY</td>\n",
              "      <td>BJET</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12, UNI</td>\n",
              "      <td>MB, MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>3009548670</td>\n",
              "      <td>real-time multimodal feedback with the cpr tutor</td>\n",
              "      <td>Daniele Di Mitri</td>\n",
              "      <td>2020</td>\n",
              "      <td>Training</td>\n",
              "      <td>LOGS,VIDEO,SENSOR,MOTION</td>\n",
              "      <td>POSE,EMG,GEST</td>\n",
              "      <td>CLS</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>AIED</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>PSY</td>\n",
              "      <td>IND</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>PROF</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>1770989706</td>\n",
              "      <td>focused or stuck together: multimodal patterns reveal triads' performance in collaborative problem solving</td>\n",
              "      <td>Hana Vrzakova</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>AUDIO,VIDEO,SCREEN,SURVEY,PPA</td>\n",
              "      <td>PROS,ACT,GEST,PPA</td>\n",
              "      <td>STATS,PATT</td>\n",
              "      <td>MID</td>\n",
              "      <td>LAK</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>3051560548</td>\n",
              "      <td>temporal analysis of multimodal data to predict collaborative learning outcomes</td>\n",
              "      <td>Jennifer K. Olsen</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>LOGS,AUDIO,EYE</td>\n",
              "      <td>GAZE,LOGS,PROS,TRANS,QUAL</td>\n",
              "      <td>REG</td>\n",
              "      <td>MID</td>\n",
              "      <td>BJET</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>147203129</td>\n",
              "      <td>multimodal learning analytics to inform learning design: lessons learned from computing education</td>\n",
              "      <td>Katerina Mangaroska</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,EYE,SENSOR,LOGS</td>\n",
              "      <td>LOGS,GAZE,EDA,PULSE,AFFECT,TEMP</td>\n",
              "      <td>CLS</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>JLA</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>2000036002</td>\n",
              "      <td>predicting learners effortful behaviour in adaptive assessment using multimodal data</td>\n",
              "      <td>Kshitij Sharma</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,EYE,SENSOR</td>\n",
              "      <td>EDA,TEMP,PULSE,EEG,GAZE,AFFECT</td>\n",
              "      <td>CLUST,CLS,PATT</td>\n",
              "      <td>MID</td>\n",
              "      <td>LAK</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>2055153191</td>\n",
              "      <td>round or rectangular tables for collaborative problem solving? a multimodal learning analytics study</td>\n",
              "      <td>Milica Vujovic</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,MOTION</td>\n",
              "      <td>POSE,GEST,ACT</td>\n",
              "      <td>STATS,QUAL</td>\n",
              "      <td>OTH</td>\n",
              "      <td>BJET</td>\n",
              "      <td>BLND</td>\n",
              "      <td>HUM, STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>3796643912</td>\n",
              "      <td>an evaluation of an adaptive learning system based on multimodal affect recognition for learners with intellectual disabilities</td>\n",
              "      <td>Penelope J. Standen</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO,LOGS,RPA</td>\n",
              "      <td>AFFECT,POSE,LOGS,RPA,GAZE,PROS,GEST</td>\n",
              "      <td>CLS,STATS</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>BJET</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>HUM, OTH, STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>2879332689</td>\n",
              "      <td>from data to insights: a layered storytelling approach for multimodal learning analytics</td>\n",
              "      <td>Roberto Martinez-Maldonado</td>\n",
              "      <td>2020</td>\n",
              "      <td>Training</td>\n",
              "      <td>LOGS,MOTION,SENSOR,RPA,VIDEO</td>\n",
              "      <td>POSE,EDA,LOGS,RPA</td>\n",
              "      <td>QUAL</td>\n",
              "      <td>OTH</td>\n",
              "      <td>CHI</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>1877483551</td>\n",
              "      <td>motion-based educational games: using multi-modal data to predict players performance</td>\n",
              "      <td>Serena Lee-Cultura</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,EYE,SENSOR</td>\n",
              "      <td>PULSE,TEMP,EDA,GAZE,POSE</td>\n",
              "      <td>CLS</td>\n",
              "      <td>MID</td>\n",
              "      <td>COG</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>3637456466</td>\n",
              "      <td>impact of inquiry interventions on students in e-learning and classroom environments using affective computing framework</td>\n",
              "      <td>T. S. Ashwin</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,PPA</td>\n",
              "      <td>AFFECT,POSE,GEST</td>\n",
              "      <td>CLS,STATS,PATT</td>\n",
              "      <td>MID</td>\n",
              "      <td>UMUAI</td>\n",
              "      <td>PHYS, VIRT</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>IND, MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>2936220551</td>\n",
              "      <td>multi-source and multimodal data fusion for predicting academic performance in blended learning university courses</td>\n",
              "      <td>Wilson Chango</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,LOGS,PPA</td>\n",
              "      <td>LOGS,POSE,RPA,ACT</td>\n",
              "      <td>CLS,QUAL,STATS</td>\n",
              "      <td>MID,LATE</td>\n",
              "      <td>CEE</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>2634033325</td>\n",
              "      <td>controlled evaluation of a multimodal system to improve oral presentation skills in a real learning setting</td>\n",
              "      <td>Xavier Ochoa</td>\n",
              "      <td>2020</td>\n",
              "      <td>Training</td>\n",
              "      <td>VIDEO,AUDIO,PPA</td>\n",
              "      <td>POSE,PROS,PPA</td>\n",
              "      <td>STATS</td>\n",
              "      <td>OTH</td>\n",
              "      <td>BJET</td>\n",
              "      <td>BLND</td>\n",
              "      <td>HUM</td>\n",
              "      <td>IND</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>123412197</td>\n",
              "      <td>utilizing multimodal data through fsqca to explain engagement in adaptive learning</td>\n",
              "      <td>Zacharoula Papamitsiou</td>\n",
              "      <td>2020</td>\n",
              "      <td>Learning</td>\n",
              "      <td>SURVEY,LOGS,EYE,SENSOR,VIDEO</td>\n",
              "      <td>PULSE,AFFECT,EEG,GAZE,LOGS,BP,TEMP,EDA,SURVEY</td>\n",
              "      <td>PATT</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>TLT</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INF</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>3809293172</td>\n",
              "      <td>blending learning analytics and embodied design to model students' comprehension of measurement using their actions, speech, and gestures</td>\n",
              "      <td>Avery H. Closser</td>\n",
              "      <td>2021</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO</td>\n",
              "      <td>RPA</td>\n",
              "      <td>CLUST,REG</td>\n",
              "      <td>MID</td>\n",
              "      <td>IJCCI</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INF</td>\n",
              "      <td>K12, UNI</td>\n",
              "      <td>MB, MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>1763513559</td>\n",
              "      <td>keep me in the loop: real-time feedback with multimodal data</td>\n",
              "      <td>Daniele Di Mitri</td>\n",
              "      <td>2021</td>\n",
              "      <td>Training</td>\n",
              "      <td>SURVEY,LOGS,VIDEO,SENSOR,MOTION</td>\n",
              "      <td>POSE,EMG,GEST,SURVEY</td>\n",
              "      <td>CLS,QUAL,STATS</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>IJAIED</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>PSY</td>\n",
              "      <td>IND</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>PROF</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>4035649049</td>\n",
              "      <td>storytelling with learner data: guiding student reflection on multimodal team data</td>\n",
              "      <td>Gloria Fernndez-Nieto</td>\n",
              "      <td>2021</td>\n",
              "      <td>Training</td>\n",
              "      <td>SENSOR,LOGS,RPA</td>\n",
              "      <td>EDA,LOGS,RPA,AFFECT</td>\n",
              "      <td>QUAL</td>\n",
              "      <td>OTH</td>\n",
              "      <td>TLT</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>3625722965</td>\n",
              "      <td>table tennis tutor: forehand strokes classification based on multimodal data and neural networks</td>\n",
              "      <td>Khaleel Asyraaf Mat Sanusi</td>\n",
              "      <td>2021</td>\n",
              "      <td>Training</td>\n",
              "      <td>VIDEO,MOTION,INTER</td>\n",
              "      <td>POSE,GEST,ACT,INTER</td>\n",
              "      <td>CLS,QUAL</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>Sensors</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>PSY</td>\n",
              "      <td>IND</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>1426267857</td>\n",
              "      <td>affect, support, and personal factors: multimodal causal models of one-on-one coaching</td>\n",
              "      <td>Lujie Karen Chen</td>\n",
              "      <td>2021</td>\n",
              "      <td>Learning</td>\n",
              "      <td>AUDIO,VIDEO,SURVEY</td>\n",
              "      <td>PROS,GAZE,TRANS,AFFECT,SURVEY</td>\n",
              "      <td>STATS,NET</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>JEDM</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>666050348</td>\n",
              "      <td>multicraft: a multimodal interface for supporting and studying learning in minecraft</td>\n",
              "      <td>Marcelo Worsley</td>\n",
              "      <td>2021</td>\n",
              "      <td>Learning</td>\n",
              "      <td>AUDIO,EYE,TEXT,VIDEO,SCREEN,INTER,SURVEY,LOGS</td>\n",
              "      <td>PROS,TRANS,GAZE,TEXT,INTER,SURVEY,LOGS</td>\n",
              "      <td>QUAL</td>\n",
              "      <td>OTH</td>\n",
              "      <td>HCII</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INF</td>\n",
              "      <td>K12</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>518268671</td>\n",
              "      <td>using multimodal learning analytics to explore collaboration in a sustainability co-located tabletop game</td>\n",
              "      <td>Mara Ximena Lpez</td>\n",
              "      <td>2021</td>\n",
              "      <td>Learning</td>\n",
              "      <td>SURVEY,LOGS,AUDIO,VIDEO</td>\n",
              "      <td>LOGS,SURVEY,GAZE,PROS</td>\n",
              "      <td>STATS</td>\n",
              "      <td>OTH</td>\n",
              "      <td>ECGBL</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>3660066725</td>\n",
              "      <td>children's play and problem solving in motion-based educational games: synergies between human annotations and multi-modal data</td>\n",
              "      <td>Serena Lee-Cultura</td>\n",
              "      <td>2021</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,SENSOR,EYE,LOGS</td>\n",
              "      <td>ACT,GAZE,EDA,PULSE,AFFECT,FATIG,LOGS,QUAL,TEMP</td>\n",
              "      <td>STATS,QUAL</td>\n",
              "      <td>OTH</td>\n",
              "      <td>IDC</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>3856280479</td>\n",
              "      <td>children's play and problem-solving in motion-based learning technologies using a multi-modal mixed methods approach</td>\n",
              "      <td>Serena Lee-Cultura</td>\n",
              "      <td>2021</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,SENSOR,EYE,LOGS</td>\n",
              "      <td>ACT,GAZE,EDA,PULSE,AFFECT,FATIG,LOGS,QUAL,TEMP,BP</td>\n",
              "      <td>STATS,QUAL,CLS</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>IJCCI</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB, MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>4277812050</td>\n",
              "      <td>improving prediction of students' performance in intelligent tutoring systems using attribute selection and ensembles of different multimodal data sources</td>\n",
              "      <td>Wilson Chango</td>\n",
              "      <td>2021</td>\n",
              "      <td>Learning</td>\n",
              "      <td>LOGS,VIDEO,EYE,PPA</td>\n",
              "      <td>AFFECT,LOGS,GAZE,PPA</td>\n",
              "      <td>CLS</td>\n",
              "      <td>HYBRID,LATE</td>\n",
              "      <td>JCHE</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNI</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>566043228</td>\n",
              "      <td>automatic student engagement in online learning environment based on neural turing machine</td>\n",
              "      <td>Xiaoyang Ma</td>\n",
              "      <td>2021</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO</td>\n",
              "      <td>POSE,GAZE</td>\n",
              "      <td>CLS</td>\n",
              "      <td>MID</td>\n",
              "      <td>IJIET</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>UNSP</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>1315379489</td>\n",
              "      <td>multimodal engagement analysis from facial videos in the classroom</td>\n",
              "      <td>mer Smer</td>\n",
              "      <td>2021</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO</td>\n",
              "      <td>POSE,AFFECT</td>\n",
              "      <td>CLS</td>\n",
              "      <td>EARLY,LATE</td>\n",
              "      <td>TAC</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>HUM, STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>1469065963</td>\n",
              "      <td>examining socially shared regulation and shared physiological arousal events with multimodal learning analytics</td>\n",
              "      <td>Andy Nguyen</td>\n",
              "      <td>2022</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO,SENSOR</td>\n",
              "      <td>QUAL,EDA</td>\n",
              "      <td>PATT,CLS,CLUST</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>BJET</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>433919853</td>\n",
              "      <td>understanding fun in learning to code: a multi-modal data approach</td>\n",
              "      <td>Gabriella Tisza</td>\n",
              "      <td>2022</td>\n",
              "      <td>Learning</td>\n",
              "      <td>SENSOR,VIDEO,PPA</td>\n",
              "      <td>TEMP,PULSE,EDA,BP,AFFECT</td>\n",
              "      <td>REG,STATS</td>\n",
              "      <td>MID</td>\n",
              "      <td>IDC</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB, MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>2273914836</td>\n",
              "      <td>many are the ways to learn identifying multi-modal behavioral profiles of collaborative learning in constructivist activities</td>\n",
              "      <td>Jauwairia Nasir</td>\n",
              "      <td>2022</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO,LOGS,PPA,SURVEY</td>\n",
              "      <td>PROS,AFFECT,GAZE,TRANS,LOGS</td>\n",
              "      <td>STATS,QUAL,CLUST,CLS</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>IJCSCL</td>\n",
              "      <td>BLND</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>32184286</td>\n",
              "      <td>once more with feeling: emotions in multimodal learning analytics</td>\n",
              "      <td>Marcus Kubsch</td>\n",
              "      <td>2022</td>\n",
              "      <td>Learning</td>\n",
              "      <td>SURVEY,PPA,AUDIO</td>\n",
              "      <td>INTER,SURVEY,TRANS,PROS,AFFECT</td>\n",
              "      <td>CLS,REG,STATS</td>\n",
              "      <td>OTH</td>\n",
              "      <td>MMLA Handbook</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB, MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>2609260641</td>\n",
              "      <td>visualizing collaboration in teamwork: a multimodal learning analytics platform for non-verbal communication</td>\n",
              "      <td>Ren Nol</td>\n",
              "      <td>2022</td>\n",
              "      <td>Learning</td>\n",
              "      <td>AUDIO,VIDEO,RPA,INTER</td>\n",
              "      <td>PROS,POSE,RPA,INTER,QUAL</td>\n",
              "      <td>QUAL</td>\n",
              "      <td>OTH</td>\n",
              "      <td>DAMLE</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>HUM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INF</td>\n",
              "      <td>PROF, UNI</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>1345598079</td>\n",
              "      <td>intermodality in multimodal learning analytics for cognitive theory development: a case from embodied design for mathematics learning</td>\n",
              "      <td>Sofia Tancredi</td>\n",
              "      <td>2022</td>\n",
              "      <td>Learning</td>\n",
              "      <td>EYE,VIDEO,AUDIO,INTER</td>\n",
              "      <td>GAZE,GEST,TRANS,POSE,INTER</td>\n",
              "      <td>PATT,QUAL,STATS</td>\n",
              "      <td>OTH</td>\n",
              "      <td>MMLA Handbook</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>IND</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>2155422499</td>\n",
              "      <td>a multimodal analysis of pair work engagement episodes: implications for emi lecturer training</td>\n",
              "      <td>Teresa Morell</td>\n",
              "      <td>2022</td>\n",
              "      <td>Training</td>\n",
              "      <td>VIDEO,AUDIO,PPA</td>\n",
              "      <td>TRANS,PPA,QUAL,POSE,ACT</td>\n",
              "      <td>QUAL</td>\n",
              "      <td>OTH</td>\n",
              "      <td>JEAP</td>\n",
              "      <td>PHYS</td>\n",
              "      <td>OTH</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>TRAIN</td>\n",
              "      <td>PROF</td>\n",
              "      <td>MF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>3754172825</td>\n",
              "      <td>detecting impasse during collaborative problem solving with multimodal learning analytics</td>\n",
              "      <td>Yingbo Ma</td>\n",
              "      <td>2022</td>\n",
              "      <td>Learning</td>\n",
              "      <td>VIDEO,AUDIO</td>\n",
              "      <td>TRANS,PROS,SPECT,GAZE,POSE</td>\n",
              "      <td>CLS</td>\n",
              "      <td>HYBRID</td>\n",
              "      <td>LAK</td>\n",
              "      <td>VIRT</td>\n",
              "      <td>STEM</td>\n",
              "      <td>MULTI</td>\n",
              "      <td>INSTR</td>\n",
              "      <td>K12</td>\n",
              "      <td>MB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2a2e13c-2446-4c0f-b656-ea0a3f777016')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d2a2e13c-2446-4c0f-b656-ea0a3f777016 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d2a2e13c-2446-4c0f-b656-ea0a3f777016');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2291daae-85a4-4abc-bade-5e9c0bc7975a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2291daae-85a4-4abc-bade-5e9c0bc7975a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2291daae-85a4-4abc-bade-5e9c0bc7975a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_466a2b58-25bc-427f-ac3a-25c5db6fcf86\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_consensus')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_466a2b58-25bc-427f-ac3a-25c5db6fcf86 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_consensus');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}